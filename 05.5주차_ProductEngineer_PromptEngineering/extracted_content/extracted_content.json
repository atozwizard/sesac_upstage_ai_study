{
  "pdfs": {
    "(EXT) [SeSAC] [Prompt Engineering] 코랩 세션_Wrap Up 리포트 (template)의 사본.pdf": {
      "filename": "(EXT) [SeSAC] [Prompt Engineering] 코랩 세션_Wrap Up 리포트 (template)의 사본.pdf",
      "char_count": 15425,
      "preview": " \n \n \n[Prompt\n \nEngineering]\n \n코랩세션\n \nWrap\n \nUp\n \n리포트\n \n작성팀:\n \n(이영기)\n \nWrap\n \nUp\n \n리포트\n \n작성\n \n내용\n \n1)\n \n논의\n \n주제\n \na)\n \n보라색으로\n \n작성된\n \n주제는\n \n예시\n \n주제로,\n \n팀\n \n내\n \n논의하고\n \n싶은\n \n주제가\n \n있다면\n \n해당\n \n주제로\n \n논의해주세요!\n \n2)\n \n팀원별\n \n핵심\n \n아이디어\n \n3)\n \n논의\n \n과정\n \n4)\n \n최종\n \n논의\n \n결과\n \n및\n \n회고\n \n \n공통\n \n예시\n \n주제\n \n(Day\n \n01\n \n-\n \nDay\n \n05)\n \n \n \nDay\n \n01\n \n코랩\n \n세션\n \n \n논문\n:\n \nLanguage\n \nModels\n \nare\n \nUnsupervised\n \nMultitask\n \nLearners\n \n(GPT -2)\n \n•\n \nUnsupervised\n \nMultitask\n \nLearning\n \n(\n비지도\n \n멀티태스크\n \n학습\n):\n \n별도의\n \n라벨링"
    },
    "[SeSAC] Lv3 Product Engineering 타운홀 미팅.pdf": {
      "filename": "[SeSAC] Lv3 Product Engineering 타운홀 미팅.pdf",
      "char_count": 6948,
      "preview": "SeSAC Level 3 \n타운홀 미팅 \nUpstage, AI Education © 2025 Upstage Co., Ltd. \n2 과정 소개 01\n커리큘럼 상세 일정 CS with AI - 자료구조와 알고리즘 \n업스테이지와 함께하는 AI Product Engineer 성장 여정 \nAI Literacy \n12월 22일 ~ 12월 29일 \n(1w) Computer Science \nwith AI \n12월 30일 ~ 1월 20일 \n(3w) AI Product \nEngineering \n1월 21일 ~ 2월 20일 \n(4w) AI Backend \nEngineering \n2월 23일 ~ 3월 9일 \n(2w) \nWhy AI \nIntroduction to AI 자료구조와 알고리즘 \n개발환경 구성 \n네트워크와 클라우드 Prompt Engineering \nAgentic Workﬂow \nLLM Product Engineering \nProject Service Deployment \nLLM Ops \n커리큘럼"
    },
    "01.강의자료/02-Basic_Prompting.pptx.pdf": {
      "filename": "02-Basic_Prompting.pptx.pdf",
      "char_count": 11228,
      "preview": "[02강] Basic Prompting & \nTutorial \n이화여자대학교 인공지능학과 조교수 © 2025 Upstage Co., Ltd. 조현수 \n2 저작권 안내 \n \n(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 \n운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. \n콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. \n유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. \n유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. \n•콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 \n•콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 \n•콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 \n•콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 \n•지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 \n•다른 정보와 결합하여 Up"
    },
    "01.강의자료/03-Advanced LLM Prompting Strategies_1.pdf": {
      "filename": "03-Advanced LLM Prompting Strategies_1.pdf",
      "char_count": 15981,
      "preview": "[03강] LLM 고급 프롬프팅 기법 (1) \n© 2025 Upstage Co., Ltd. 조현수 \n이화여자대학교 인공지능학과 조교수 \n2 강의 목표 \n학습 목표 \n•LLM 고급 프롬프팅 기법에 대한 분류 체계에 대해 이해할 수 있다. \n•해당 체계 중 지시사항 및 예시 관련 프롬프팅 기법을 학습할 수 있다. \n\n3 01. LLM 고급 프롬프팅 기법 분류 \n(1) LLM 고급 프롬프팅 기법 분류 (예시, 지시사항, 검증) \n02. 지시사항 관련 LLM 프롬프팅 기법 \n(1) Zero-shot CoT \n(2) Plan-and-Solve Prompting \n03. 예시 관련 LLM 프롬프팅 기법 \n(1) Chain-of-Thought(CoT) \n(2) Self-Ask \n(3) Least-to-most prompting 목차 \n4 LLM 고급 프롬프팅 기법 분류 01\nLLM 고급 프롬프팅 기법 분류 (지시사항, 예시, 검증) \n5 LLM 고급 프롬프팅 기법 분류 (지시사항, 예시) 03 "
    },
    "01.강의자료/09-Related_Works_Trends.pptx.pdf": {
      "filename": "09-Related_Works_Trends.pptx.pdf",
      "char_count": 7433,
      "preview": "[9강] Related Works & Trends \n조현수 \n이화여자대학교 인공지능학과 조교수 \n© 2025 Upstage Co., Ltd. \n2 저작권 안내 \n \n(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 \n운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. \n콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. \n유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. \n유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. \n● 콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 \n● 콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 \n● 콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 \n● 콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 \n● 지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 \n● 다른 정보와 결합하여 "
    },
    "01.강의자료/1-01-Introduction.pptx.pdf": {
      "filename": "1-01-Introduction.pptx.pdf",
      "char_count": 7954,
      "preview": "[01강] Introduction \n조현수 \n이화여자대학교 인공지능학과 조교수 © 2025 Upstage Co., Ltd. \n2 강의 소개 \nLLM을 효과적으로 활용하기 위한 프롬프트 엔지니어링에 대한 이해 \n•프롬프트의 개념과 역할 이해 \n•프롬프트 엔지니어링의 핵심 원리와 기본 접근 \n•고도화된 설계 사고와 실전 적용 흐름 \n•RAG 등 외부 지식 결합 방식의 개요 \n•에이전트형 AI로 확장되는 전체 로드맵 소개 \n\n3 강의 목표 \n학습 목표 \n•LLM의 개념과 한계를 이해할 수 있다. \n•인간과 모델 간의 간극을 설명할 수 있다. \n•Prompt와 Prompt Engineering의 역할을 이해하고 실무 문제를 해결하기 위한 프롬프트를 설계할 수 있다. \n4 01. Large Language Model \n(1) Alignment Learning \n(2) Prompt \n02. Prompt Engineering \n(1) Introduce Modules \n(2) Agentic AI "
    },
    "01.강의자료/1-08-Prompt-Based LLM Security Vulnerabilities and Safety Validation.pdf": {
      "filename": "1-08-Prompt-Based LLM Security Vulnerabilities and Safety Validation.pdf",
      "char_count": 12466,
      "preview": "[08강] 프롬프트 기반 LLM 보안 \n취약점과 안전성 검증 \n조현수 \n이화여자대학교 인공지능학과 조교수 © 2025 Upstage Co., Ltd. \n2 강의 목표 \n학습목표 \n•LLM을 공격하는 방법에 대한 이해 ‒ 프롬프트 인젝션, 탈옥 \n•LLM 공격을 방어하기 위한 보안 방식 이해 ‒ 레드 팀, 블루 팀 \n[1] Xu, Wenrui, and Keshab K. Parhi. \"A Survey of Attacks on Large Language Models.\" arXiv preprint arXiv:2505.12567 (2025). \n3 01. 프롬프트 기반 LLM 공격 방법 \n(1) 탈옥 (Jailbreak) \n(2) 프롬프트 인젝션 \n02. 사이버 보안(블루 팀 vs. 레드 팀) \n(1) 사이버 보안 \n(2) 공격 보안 (레드 팀) \n(3) 방어 보안 (블루 팀) \n목차 \n4 프롬프트 기반 LLM 공격 방법 01\n5 LLM 보안 취약점 08 프롬프트 기반 LLM 보안 취약점과 "
    },
    "01.강의자료/10-Agentic_AI_Summary.pptx.pdf": {
      "filename": "10-Agentic_AI_Summary.pptx.pdf",
      "char_count": 12826,
      "preview": "[10강] Agentic AI & Summary © 2025 Upstage Co., Ltd. 조현수 \n이화여자대학교 인공지능학과 조교수 \n2 저작권 안내 \n \n(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 \n운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. \n콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. \n유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. \n유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. \n•콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 \n•콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 \n•콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 \n•콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 \n•지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 \n•다른 정보와 결합하여 Upstage E"
    },
    "01.강의자료/2-04-Advanced LLM Prompting Strategies_2.pdf": {
      "filename": "2-04-Advanced LLM Prompting Strategies_2.pdf",
      "char_count": 16339,
      "preview": "[04강] LLM 고급 프롬프팅 기법 (2) \n조현수 \n이화여자대학교 인공지능학과 조교수 © 2025 Upstage Co., Ltd. \n2 강의 목표 \n학습 목표 \n•LLM 고급 프롬프팅 기법의 분류 체계 중 검증 관련 프롬프팅 기법을 학습한다. \n\n3 목차 \n01. 검증 관련 LLM 프롬프팅 기법 \n(1) Self-consistency \n(2) Self-veriﬁcation \n(3) Self-reﬁne \n(4) Tree-of-Thoughts (ToT) \n\n4 검증 관련 LLM 프롬프팅 기법 01\nSelf-consistency / Self-veriﬁcation / Self-reﬁne / ToT \n5 검증 관련 LLM 프롬프팅 기법 04 LLM 고급 프롬프팅 기법 (2) \n검증 관련 LLM 프롬프팅 기법 개요 \n•모델  답변에 대한 검증을 유도하는 프롬프트 를 통해 답변의 질을 향상시키는 방법 \n\n검증 관련 LLM 프롬프팅 기법 개요 \n본 강의에서는 다음과 같은 모듈을 구성하고, 각 "
    },
    "01.강의자료/Chain-of-Thought Prompting Elicits Reasoning.pdf": {
      "filename": "Chain-of-Thought Prompting Elicits Reasoning.pdf",
      "char_count": 134038,
      "preview": "Chain-of-Thought Prompting Elicits Reasoning\nin Large Language Models\nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\nBrian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\nGoogle Research, Brain Team\n{jasonwei,dennyzhou}@google.com\nAbstract\nWe explore how generating a chain of thought —a series of intermediate reasoning\nsteps—signiﬁcantly improves the ability of large language models to perform\ncomplex reasoning. In particular, we show how such reasoning abilities emerge\nnaturally in sufﬁcie"
    },
    "01.강의자료/Exploring Agentic Workflows_ A Deep Dive into AI-Enhanced Productivity.pdf": {
      "filename": "Exploring Agentic Workflows_ A Deep Dive into AI-Enhanced Productivity.pdf",
      "char_count": 23049,
      "preview": "Exploring\n \nAgentic\n \nWorkflows:\n \nA\n \nDeep\n \nDive\n \ninto\n \nAI-Enhanced\n \nProductivity\n \nDecember\n \n16,\n \n2024\n \n \nAD\n \n \nFiltrix.ai\n \n–\n \nAI\n \nImage\n \nGeneration\n \nTransform\n \ntext\n \ninto\n \nstunning\n \nvisuals\n \nwith\n \nour\n \nadvanced\n \nAI\n \ntechnology .\n \nPerfect\n \nfor\n \ncontent\n \ncreators\n \nwho\n \nneed\n \nhigh-quality\n \nimages\n \nwithout\n \nthe\n \nhassle.\n \nWhy\n \nchoose\n \nFiltrix.ai?\n \n✓\n \nInstant\n \nresults\n    \n✓\n \nMultiple\n \nstyles\n    \n✓\n \nHigh\n \nresolution\n    \n✓\n \nCommercial\n \nlicense\n \nGet\n \nS"
    },
    "01.강의자료/FaithfulRAG Fact-Level Conflict Modeling for Context-Faithful.pdf": {
      "filename": "FaithfulRAG Fact-Level Conflict Modeling for Context-Faithful.pdf",
      "char_count": 74240,
      "preview": "FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful\nRetrieval-Augmented Generation\nQinggang Zhang1*, Zhishang Xiang2*, Yilin Xiao3, Le Wang4, Junhui Li5,\nXinrun Wang6,Jinsong Su1,7†\n1School of Informatics, Xiamen University\n2Institute of Artificial Intelligence, Xiamen University\n3The Hong Kong Polytechnic University4Migu Meland Co., Ltd5Soochow University\n6Singapore Management University7Shanghai Artificial Intelligence Laboratory\n{zqg.zhang, xzs.xiang}@hotmail.com jssu@xmu.edu.cn\nAb"
    },
    "01.강의자료/Large Language Models are Better Reasoners with Self-Verification.pdf": {
      "filename": "Large Language Models are Better Reasoners with Self-Verification.pdf",
      "char_count": 105843,
      "preview": "Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 2550–2575\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLarge Language Models are Better Reasoners with Self-Verification\nYixuan Weng1∗, Minjun Zhu1,2∗, Fei Xia1,2, Bin Li3,\nShizhu He1,2†, Shengping Liu4, Bin Sun3, Kang Liu1,2,5, Jun Zhao1,2\n1The Laboratory of Cognition and Decision Intelligence for Complex Systems, IA, CAS\n2School of Artificial Intelligence, University of Chinese Academy of Scien"
    },
    "01.강의자료/Prompt Engineering_07_Advanced RAG_2.pdf": {
      "filename": "Prompt Engineering_07_Advanced RAG_2.pdf",
      "char_count": 12119,
      "preview": "[7강] Advanced RAG (2) © 2025 Upstage Co., Ltd. 조현수 \n이화여자대학교 인공지능학과 조교수 \n2 저작권 안내 \n \n(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 \n운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. \n콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. \n유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. \n유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. \n● 콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 \n● 콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 \n● 콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 \n● 콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 \n● 지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 \n● 다른 정보와 결합하여 Upstage "
    },
    "01.강의자료/Prompting Large Vision-Language Models for Compositional Reasoning.pdf": {
      "filename": "Prompting Large Vision-Language Models for Compositional Reasoning.pdf",
      "char_count": 56912,
      "preview": "Prompting Large Vision-Language Models for Compositional Reasoning\nTimothy Ossowski1, Ming Jiang3, Junjie Hu1,2\n1Department of Computer Science,2Department of Biostatistics and Medical Informatics\nUniversity of Wisconsin, Madison, WI, USA\n3Department of Human-centered Computing, Indiana University, Indianapolis, IN, USA\nossowski@wisc.edu ,mj200@iu.edu ,junjie.hu@wisc.edu\nAbstract\nVision-language models such as CLIP have\nshown impressive capabilities in encoding texts\nand images into aligned embe"
    },
    "01.강의자료/Red Teaming Language Models with Language Models.pdf": {
      "filename": "Red Teaming Language Models with Language Models.pdf",
      "char_count": 118021,
      "preview": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing , pages 3419–3448\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nRed Teaming Language Models with Language Models\nWARNING: This paper contains model outputs which are offensive in nature.\nEthan Perez1 2Saffron Huang1Francis Song1Trevor Cai1Roman Ring1\nJohn Aslanides1Amelia Glaese1Nat McAleese1Geoffrey Irving1\n1DeepMind,2New York University\nperez@nyu.edu\nAbstract\nLanguage Models (LMs) often"
    }
  },
  "notebooks": {
    "02.daily mission/[Daily_Mission]_(Day1_기본_심화)_Prompt_Engineering을_적용하여_MMLU_풀이하기(문제)_ipynb의_사본 (1).ipynb": {
      "filename": "[Daily_Mission]_(Day1_기본_심화)_Prompt_Engineering을_적용하여_MMLU_풀이하기(문제)_ipynb의_사본 (1).ipynb",
      "char_count": 19191,
      "preview": "# [Daily Mission] Day 1(기본) — MMLU 데이터 활용하기\n\n## 미션 소개\n\n이번 Daily Mission에서는 **LLM 성능 평가의 표준 벤치마크 중 하나인 MMLU 데이터셋**을 활용해 **SOLAR-mini 모델의 Baseline 성능을 직접 측정하는 평가 파이프라인**을 만들어봅니다.\n\n이를 통해 동일한 MMLU 평가 파이프라인을 기준으로 **모델을 어떻게 평가해야 하는지**를 이해하는 것이 목표입니다.\n\n일반적으로 LLM의 성능은 “잘 대답하는 것 같다”라는 감각적인 평가에 의존하기 쉽습니다. 하지만 실제 연구나 실무에서는 정량적인 기준(벤치마크)을 통해 모델을 비교하고 개선합니다.\n\n이번 미션의 목표는 **점수 자체가 아니라**,  \n> 👉 *“LLM을 어떻게 평가하는가?”*  \n> 👉 *“평가를 코드로 어떻게 구현하는가?”*  \n를 이해하는 것입니다.\n\n---\n\n## 이번 미션에서 다룰 내용\n\n이번 미션에서는 다음과 같은 흐름을 따라갑니다.\n\n1."
    },
    "02.daily mission/[Daily_Mission]_(Day2_기본_심화)_LLM_고급_프롬프팅_기법(문제)_ipynb의_사본.ipynb": {
      "filename": "[Daily_Mission]_(Day2_기본_심화)_LLM_고급_프롬프팅_기법(문제)_ipynb의_사본.ipynb",
      "char_count": 23684,
      "preview": "# Day2 | 고급 프롬프팅 기법 실습 (기본 + 심화)\n\n## 이 실습을 왜 하나요?\nDay1에서는 **(1) 데이터 로드 → (2) 프롬프트 생성 → (3) 모델 호출(API) → (4) 정답 추출 → (5) 채점/평가**까지의 기본 파이프라인을 만들었습니다.\n\n하지만 실제로는 **같은 모델/같은 데이터**라도 프롬프트 구조에 따라 다음과 같은 오류가 크게 달라집니다.\n- 계산/추론 과정 생략(논리 점프)\n- 조건 누락/오독\n- 선택지(A/B/C/D) 혼동\n- 답변 형식이 불안정해서 자동 채점이 어려움\n\nDay2에서는 **모델과 데이터는 고정**하고, **프롬프트(입력 텍스트)만 바꿔가며** 결과를 비교합니다.  \n즉, “코딩”보다 **프롬프트 설계**에 초점을 둔 실습입니다.\n\n---\n\n## 오늘의 목표\n- Day1에서 사용한 **MMLU 로딩/평가 코드**를 그대로 유지\n- Day1에서 사용한 **프롬프트 생성 함수**를 그대로 유지\n- Day2에서 새로 다루는 기법(Zer"
    },
    "02.daily mission/[Daily_Mission]_(Day4_기본)_RAG_Knowledge_Conflict(문제)_ipynb의_사본.ipynb": {
      "filename": "[Daily_Mission]_(Day4_기본)_RAG_Knowledge_Conflict(문제)_ipynb의_사본.ipynb",
      "char_count": 75772,
      "preview": "# Day 4. RAG 기반 Knowledge Conflict 탐지 및 완화\n\n본 실습은 강의 7강 「Advanced RAG (2)」 중 Knowledge Conflict 파트를 바탕으로 설계되었습니다.\n\n\n강의에서는 LLM이 답변을 생성할 때,\n\n\n**모델 내부에 이미 학습된 지식(Parametric Knowledge)** 과\n외부에서 주어진 문서 정보(External Knowledge, Context) 사이에\n\n\n서로 다른 정보가 존재할 경우,\n모델이 어떤 정보를 신뢰하고 선택하는지가 중요한 문제임을 다루었습니다.\n\n---\n\n## 학습 포인트\n- LLM이 생성한 답변과 근거 문서 간 **conflict detection** 체험  \n  - “근거에 없는 단정”을 막고, “상충 근거”를 안전하게 처리\n- RAG 환경에서 발생하는 **Knowledge Conflict** 개념 이해  \n  - 동일 질문에 대해 **서로 다른 문서가 상반된 주장**을 제공하는 상황\n\n---\n\n## 오늘"
    },
    "02.daily mission/[Daily_Mission]_(Day4_심화)_Prompt_Guardrails(문제)_ipynb의_사본.ipynb": {
      "filename": "[Daily_Mission]_(Day4_심화)_Prompt_Guardrails(문제)_ipynb의_사본.ipynb",
      "char_count": 18573,
      "preview": "# (Day8) 프롬프트 기반 LLM 보안 취약점과 안전성 검증 — 미션(문제)\n\n## 이 미션을 왜 하나요?\n강의 자료(08강)에서는 **프롬프트 자체가 공격 벡터**가 될 수 있고, LLM이 지시(Instruction)와 데이터(Data)를 같은 컨텍스트로 처리하면서\n경계가 무너지면 공격자가 모델의 제어권을 가져갈 수 있다고 배웠습니다.\n\n특히 대표 공격이 두 가지입니다.\n\n- **프롬프트 인젝션(Prompt Injection)**: 문서/입력 데이터에 *숨은 지시*를 섞어 넣어, 원래 작업 대신 공격자가 원하는 작업을 수행하게 만드는 공격\n- **탈옥(Jailbreak)**: 모델의 안전 제한·가드레일을 우회하여, 금지된 행동을 하도록 만드는 공격\n- 이번 미션에서는 프롬프트 인젝션 공격만 한정하여 다룹니다.\n\n이번 미션은 강의에서 배운 내용을 코드 레벨에서 재현(레드팀)하고,\n그 다음 프롬프트 가드레일(블루팀)로 방어를 적용해 통과율을 올리는 실습입니다.\n\n> ⚠️ 실습의 목"
    },
    "02.daily mission/[Daily_Mission]_(Day4_심화)_Prompt_Guardrails(정답).ipynb": {
      "filename": "[Daily_Mission]_(Day4_심화)_Prompt_Guardrails(정답).ipynb",
      "char_count": 16833,
      "preview": "# (Day8) 프롬프트 기반 LLM 보안 취약점과 안전성 검증 — 미션(문제)\n\n## 이 미션을 왜 하나요?\n강의 자료(08강)에서는 **프롬프트 자체가 공격 벡터**가 될 수 있고, LLM이 지시(Instruction)와 데이터(Data)를 같은 컨텍스트로 처리하면서\n경계가 무너지면 공격자가 모델의 제어권을 가져갈 수 있다고 배웠습니다.\n\n특히 대표 공격이 두 가지입니다.\n\n- **프롬프트 인젝션(Prompt Injection)**: 문서/입력 데이터에 *숨은 지시*를 섞어 넣어, 원래 작업 대신 공격자가 원하는 작업을 수행하게 만드는 공격\n- **탈옥(Jailbreak)**: 모델의 안전 제한·가드레일을 우회하여, 금지된 행동을 하도록 만드는 공격\n- 이번 미션에서는 프롬프트 인젝션 공격만 한정하여 다룹니다.\n\n이번 미션은 강의에서 배운 내용을 코드 레벨에서 재현(레드팀)하고,\n그 다음 프롬프트 가드레일(블루팀)로 방어를 적용해 통과율을 올리는 실습입니다.\n\n> ⚠️ 실습의 목"
    },
    "02.daily mission/[Daily_Mission]_(Day5_기본)_Visual–Text_Embedding_Alignment_이해하기(문제)_ipynb의_사본.ipynb": {
      "filename": "[Daily_Mission]_(Day5_기본)_Visual–Text_Embedding_Alignment_이해하기(문제)_ipynb의_사본.ipynb",
      "char_count": 34113,
      "preview": "# [Daily Mission] Day 5(기본) — Visual–Text Embedding Alignment 이해하기\n이미지와 텍스트는 어떻게 같은 의미 공간에 놓이는가?\n\n## 미션소개\n\n이번 Daily Mission에서는  \nVisual Prompt Engineering의 근본 원리인 이미지–텍스트 임베딩 정렬(Embedding Alignment)을 직접 실험을 통해 이해합니다.\n\n멀티모달 모델은 이미지를 단순히 “텍스트로 변환해서” 이해하지 않습니다.  \n대신 이미지와 텍스트를 각각 벡터(embedding)로 변환한 뒤,  \n의미가 비슷한 이미지와 텍스트가 **같은 임베딩 공간에서 가깝게 위치하도록 학습**됩니다.\n\n즉,  \n> 우리가 이미지를 잘 이해하게 만드는 프롬프트를 작성한다는 것은  \n> 결국 **이미지 임베딩과 텍스트 임베딩이 잘 정렬되도록 돕는 과정**입니다.\n\n---\n\n## 이번 미션의 목표\n\n이번 미션의 목표는 다음과 같습니다.\n\n- 이미지와 텍스트가 각각 e"
    },
    "02.daily mission/[Daily_Mission]_(Day5_심화)_Tool_selector_만들기(문제).ipynb": {
      "filename": "[Daily_Mission]_(Day5_심화)_Tool_selector_만들기(문제).ipynb",
      "char_count": 10391,
      "preview": "# 🔍[Daily Mission] Day 5 - 심화 미션 — Tool Selector 만들기\n\n## 미션 소개\n\n지금까지 우리는 LLM을 사용해:\n- 질문을 던지고\n- 답변을 생성하며\n- 그 결과를 평가해왔습니다.\n\n하지만 실제로 LLM이 활용되는 많은 시스템에서는 모델이 **바로 답을 생성하지 않는 경우**가 더 많습니다.\n\n대신 모델은 먼저 이런 판단을 해야 합니다.\n\n> ❓ 이 질문은 계산이 필요한가?  \n> ❓ 외부 정보를 가져와야 하는가?  \n> ❓ 아니면 그냥 대화로 처리하면 되는가?\n\n이처럼 **상황에 따라 행동을 선택하는 능력**이 바로 Agentic AI의 핵심입니다.\n\n## 심화 미션의 목표\n\n이번 심화 미션에서는 LLM이 사용자의 질문을 보고 **적절한 도구를 선택하는 역할**을 수행하도록 합니다.\n\n즉, LLM은:\n- 질문에 바로 답하지 않고\n- 미리 정의된 도구 목록 중 하나를 선택하며\n- 그 결과를 구조화된 형식(JSON)으로 출력합니다.\n\n이것이 바로 도"
    },
    "02.daily mission/[Daily_Mission]_(Day5_심화)_Tool_selector_만들기(정답)_ipynb의_사본.ipynb": {
      "filename": "[Daily_Mission]_(Day5_심화)_Tool_selector_만들기(정답)_ipynb의_사본.ipynb",
      "char_count": 11117,
      "preview": "# 🔍[Daily Mission] Day 5 - 심화 미션 — Tool Selector 만들기\n\n## 미션 소개\n\n지금까지 우리는 LLM을 사용해:\n- 질문을 던지고\n- 답변을 생성하며\n- 그 결과를 평가해왔습니다.\n\n하지만 실제로 LLM이 활용되는 많은 시스템에서는 모델이 **바로 답을 생성하지 않는 경우**가 더 많습니다.\n\n대신 모델은 먼저 이런 판단을 해야 합니다.\n\n> ❓ 이 질문은 계산이 필요한가?  \n> ❓ 외부 정보를 가져와야 하는가?  \n> ❓ 아니면 그냥 대화로 처리하면 되는가?\n\n이처럼 **상황에 따라 행동을 선택하는 능력**이 바로 Agentic AI의 핵심입니다.\n\n## 심화 미션의 목표\n\n이번 심화 미션에서는 LLM이 사용자의 질문을 보고 **적절한 도구를 선택하는 역할**을 수행하도록 합니다.\n\n즉, LLM은:\n- 질문에 바로 답하지 않고\n- 미리 정의된 도구 목록 중 하나를 선택하며\n- 그 결과를 구조화된 형식(JSON)으로 출력합니다.\n\n이것이 바로 도"
    }
  }
}