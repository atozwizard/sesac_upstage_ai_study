[7강] Advanced RAG (2) © 2025 Upstage Co., Ltd. 조현수 
이화여자대학교 인공지능학과 조교수 
2 저작권 안내 
 
(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 
운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. 
콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. 
유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. 
유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. 
● 콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 
● 콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 
● 콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 
● 콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 
● 지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 
● 다른 정보와 결합하여 Upstage Education의 콘텐츠임을 알아볼 수 있는 저작물을 작성, 공개하는 행위 
● 제공된 데이터의 일부 혹은 전부를 Upstage Education 프로젝트/실습 수행 이외의 목적으로 사용하는 행위 
3 강의 목표 
학습 목표 
● 전체 RAG 파이프라인 고도화 기법 중 Graph RAG, RAPTOR에 대해 이해하고 설명할 수 있다. 
● Knowledge Conﬂict의 원인을 분석하고 해결방법에 대해 설명할 수 있다. 
4 01. 전체 RAG 파이프라인 고도화 
(1) Modular RAG 
(2) Self-RAG 
02.  전체 RAG 파이프라인 고도화 (2) 
(1) Graph RAG 
(2) RAPTOR 
03. Knowledge Conﬂict 
(1) Context-Memory Conﬂict 
(2) Inter-Memory Conﬂict 
(3) Intra-Memory Conﬂict 
목차 
5 전체 RAG 파이프라인 고도화 03
Modular RAG, Self-RAG 
6 Modular RAG 
07 Advanced RAG (2) 
Prompt Engineering ~ Modular RAG 
● Prompt Engineering : 외부 지식 없이 LLM의 내부 파라미터 
(지식)에만 의존하며, 프롬프트 기법(CoT 등)을 통해 추론 능력을 
극대화하는 단계 
● Naive RAG : “질문 → 검색 → 답변"이라는 고정된 단선적 
파이프라인을 구축하여 외부 지식을 주입하기 시작함 
● Advanced RAG : Naive RAG의 한계를 극복하기 위해 여러 
기법들 적용함 (Query 강화, Chunking, Reranking, etc) 
● Modular RAG 단계:  고정된 흐름을 탈피하여, 특정 기능을 가진 
'모듈'들을 레고 블록처럼 조립하는 단계. 문제의 성격에 따라 검색 모듈을 교체하거나 
추론 루프를 추가하는 등 고도의 적응성(Adaptability)을 제공함 
Gao, Yunfan, et al. "Retrieval-augmented generation for large language models: A survey." arXiv preprint arXiv:2312.10997  2.1 (2023).  

7 Modular RAG 
07 Advanced RAG (2) 
Naive RAG의 한계: 경직성 
● 기존 RAG는 고정된 파이프라인으로 작동 (검색 → 생성) 
● 질문의 유형(단순 사실 질문, 요약, 비교, 복잡한 추론)과 상관없이 항상 동일한 검색 및 생성 방식을 적용함 
● 문제점 : 모든 질문에 최적화된 하나의 '만능 파이프라인'은 존재하지 x 
○ 낮은 정밀도와 재현율(Low Precision & Recall): 검색된 문서가 질문과 상관없거나(Noise), 
정답을 내기 위해 꼭 필요한 정보가 누락되는 경우가 잦음 
○ 특정 작업에 강한 기술(예: 요약)을 다른 작업(예: 사실 검색)에 적용해 오히려 성능이 하락함 
● Modular RAG 방식 
○ RAG를 기능별로 독립된 '모듈(Module)'로 분리하고, 질문의 성격에 따라 
필요한 모듈을 선택적으로, 동적으로 조합하여 사용하는 구조 
○ i.e. 레고 블록이나 주방의 다양한 도구처럼, 필요할 때 원하는 도구만 꺼내 쓰는 방식 
8 Modular RAG 
07 Advanced RAG (2) 
Modular RAG의 다양한 모듈 
● Search : 단순 벡터 검색을 넘어 DB, 지식 그래프(KG), 웹 엔진 등 
다양한 소스에 직접 쿼리 수행 
● RAG-Fusion : 사용자의 질문을 다각도로 확장(Multi-query)하여 
병렬 검색 후 결과 재정렬 
● Memory : 과거의 검색 결과나 LLM의 이전 답변을 기억하여 반복적인 
자가 보완 수행 
● Routing : 질문의 성격에 따라 요약이 필요한지, 특정 DB 조회가 필요 
한지 경로를 결정 
● Predict : 검색 전 LLM이 미리 답을 예측해보고, 그 내용을 바탕으로 검색 쿼리 정제 
● Task Adapter : 특정 작업(Zero-shot, Few-shot 등)에 맞춰 프롬프트나 리트리버를 자동 최적화 
Gao, Yunfan, et al. "Retrieval-augmented generation for large language models: A survey." arXiv preprint arXiv:2312.10997  2.1 (2023).  

9 Self-RAG (Asai et al, 2023) 
07 Advanced RAG (2) 
Self-RAG 배경 
● 무조건적인 검색이 정답인가? 
● 일반적인 RAG : “질문이 들어오면 무조건 문서를 검색하는 방식”의 2가지 문제 존재 
○ 불필요한 검색: 모델의 내부 지식만으로 충분한데도 검색을 수행하여 비용과 시간을 낭비함 
○ 저품질 답변: 검색된 문서가 질문과 상관없거나(Irrelevant), 문서 내용과 다른 거짓정보 
(Hallucination)를 생성해도 이를 필터링할 장치가 부족함 
Liu, H., Ren, X., Luan, Y., et al. (2023). Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reﬂection. ICLR  2024 
리트리버가 'Texas'라는 단어만 
보고 질문과 상관없는 '인기 아기 
이름' 문서를 가져옴 문서에는 캘리포니아가 '가상의 섬' 
이름에서 유래했다고 되어 있는데, 
모델은 멋대로 '크리스토퍼 
콜럼버스'라고 잘못된 연결을 함 
검색된 문서에 없는 '미국 부족' 
이야기를 스스로 지어내어 답변함 
10 Self-RAG (Asai et al, 2023) 
07 Advanced RAG (2) 
핵심 메커니즘: Reﬂection Tokens 
Self-RAG는 모델이 답변을 생성하면서 동시에 자신의 상태를 나타내는 특수 토큰을 내뱉도록 학습시킴 
● 토큰: 
● Retrieve : "지금 검색이 필요한가?"를 결정 
● Is-Rel  (Relevance) : "가져온 문서가 질문에 도움이 되는가?"를 판단 
● Is-Sup  (Supported) : "생성한 답변이 문서의 증거에 기반하는가?” 를 체크 
● Is-Use  (Utility) : "최종 답변이 유용한가?"를 5단계로 평가 
Liu, H., Ren, X., Luan, Y., et al. (2023). Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reﬂection. ICLR  2024 
11 Self-RAG (Asai et al, 2023) 
07 Advanced RAG (2) 
작동 프로세스 
1. 검색 판단:  질문을 보고 Retrieve  토큰을 통해 검색 여부를 결정 
2. 병렬 생성:  검색이 필요하다면 여러 문서를 가져와, 각 문서별로 답변 후보군을 동시에 생성 
( 그림 ) 검색된 1, 2, 3번 문서들을 바탕으로 각각의 답변 후보군을 동시에 생성 
3. 자기 비판(Critique):  생성된 각 후보군에 대해 Is-Rel , Is-Sup , Is-Use  를 평가하여 점수를 책정 
( 그림 )                     ㅡ               태그를 통해 확인 가능 
4. 최종 선택:  가장 높은 점수를 받은 답변을 최종 출력 
( 그림 ) “1 > 3 > 2" , 1번을 답변으로 선택 
Liu, H., Ren, X., Luan, Y., et al. (2023). Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reﬂection. ICLR  2024 
12 전체 RAG 파이프라인 고도화 (2) 01
Graph RAG, RAPTOR 
13 Graph RAG 
07 Advanced RAG (2) 
일반적 RAG의 장점 
● RAG : 외부 지식을 끌어와서 LLM이 더 정확하고 사실 기반 답변/생성을 하게 돕는 방식 
○ 텍스트를 조각(Chunk)으로 나눠 저장함: 단편적인 정보만을 파악할 수 있음 
○ 특정 사실(예: "A의 생일은?")을 찾는 데는 강함 

14 Graph RAG 
07 Advanced RAG (2) 
일반적 RAG의 한계 
● 전역적 질문 (Global Query), 다단계 추론 (Multi-hop reasoning) 질문에 한계 존재 
○ 전역적 질문: "이 문서 전체의 핵심 주제가 뭐야?"와 같이 전체를 관통하는 질문 
○ 다단계 추론: 서로 다른 문서에 흩어진 정보들을 종합해서 답변해야 하는 경우 
○ 이번 분기 매출이 목표를 못 맞춘 핵심 원인? 
○ 문서 A: 광고비 증가 
○ 문서 B: 전환율 하락 
○ 문서 C: 재고 이슈로 배송 지연 
○ 여러 요인 연결해서 원인 사슬을 만들어야 함 

15 Graph RAG 
07 Advanced RAG (2) 
Graph RAG? 
● Graph RAG : 기존의 지식을 구조화된 그래프로 변환해 관계 정보를 활용한 검색/응답 방식을 쓰는 접근 
○ 질문과 관련된 핵심 노드(Node)로 정의 
○ 데이터 간의 명시적 관계를 선(Edge)으로 정의 
○ 각 노드와 연결된 주변 정보까지 함께 탐색하는 방식 
○ 구조적으로 복잡해지지만, 단순 RAG에 비해 복합적 추론에 강함.  
Zhu, X., et al. "Knowledge Graph-Guided Retrieval Augmented Generation. arXiv 2025." arXiv preprint arXiv:2502.06864 .

16 Graph RAG 메커니즘 
07 Advanced RAG (2) 
Knowledge Graph 구축 
비정형 텍스트에서 지식 그래프로의 변환 과정 
1. 문서 텍스트에서 개체(Entity)와 관계(Relationship)를 추출 (예: 팀 쿡, is_ceo_of, 애플) 
2. Entity 연결: 서로 다른 이름이 같은 개체임을 파악하여 노드 통합 (예: ʻTim’ , ʻTimothy’ , ʻCook’) 
3. 그래프 구축: 온톨로지 규칙에 따라 정제된 데이터를 그래프 DB에 저장 (예: Neo4j 등) 
티모시  도널드  " 팀" 쿡은 
애플의  최고경영자를  맡은 
미국 기업인이다 . 팀 쿡은 
이전에  애플 공동 창업자인  
스티브  잡스 밑에서  회사 
최고운영책임자를  맡았다 . 팀 
쿡은 1998 년 3 월 애플의  
전세계  영업 담당 수석 
부사장으로  입사한  후 전세계  
영업 및 영업 담당 전무를  
역임했다 .(팀 쿡, is_ceo_of, 애플) 

그래프 기반 검색 
1. Query를 엔티티(entity)와 관계(relation) 단위로 분해 
● “팀 쿡의 역할은 무엇인가?” → {ʻ팀 쿡' , ʻ역할' , ?} 
● 질문과 유사한 핵심 노드를 포착 
2. Knowledge Graph를 따라 해당 노드와 연관된 인접 노드/경로를 탐색 및 추출 (Local) 
● (팀 쿡  — is_ceo _of → 애플) 
3. 컨텍스트 구성: 추출된 지식을 LLM 프롬프트 입력으로 활용 
17 Graph RAG 메커니즘 
07 Advanced RAG (2) 
Recursive Abstractive Processing for Tree-Organized Retrieval 
● 문서를 '트리 구조'로 계층화하여 아주 세부적인 정보부터 전체를 아우르는 요약 정보까지 모두 잡아내는 RAG 방식 
● 배경: GraphRAG와 마찬가지로 RAG의 '단편적 정보(Chunk) 검색'의 한계를 극복하고 전역적 질문(Global Query)에 대응하기 
위해 제안됨 (예: "이 소설의 전반적인 주제가 뭐야?" , "이 기술 보고서에서 강조하는 핵심 가치가 뭐야?") 
18 RAPTOR (Sarthi et al, 2024) 07 Advanced RAG (2) 
Xu, Rongwu, et al. "Knowledge conflicts for llms: A survey." arXiv preprint arXiv:2403.08319  (2024). 

RAPTOR의 핵심 메커니즘 
작은 정보들을 묶어서 요약하고, 그 요약본들을 다시 묶어서 더 큰 요약본을 만드는 재귀적 과정 
1. 계층적 군집화:  의미적으로 유사한 텍스트 조각들을 모델(GMM 등)을 통해 그룹화 
2. 요약:  묶인 조각들을 LLM에 넣어 하나의 요약된 '부모 노드'를 생성 
3. 트리 구조 구축:  이 과정을 반복하여, 가장 아래에는 원본 청크(Leaf)가 있고, 위로 갈수록 더 넓은 범위를 아우르는 요약본(Root)이 
존재하는 트리 구조를 완성 
19 RAPTOR (Sarthi et al, 2024) 07 Advanced RAG (2) 
Xu, Rongwu, et al. "Knowledge conflicts for llms: A survey." arXiv preprint arXiv:2403.08319  (2024). 
원본 청크 요약본 
검색 방식 
1. 트리 구조 구축 (Tree Construction) 
2. 검색 (Retrieval): 트리의 모든 층위(All levels)에서 사용자의 질문과 관련된 노드들을 동시에 검색 
● 구체적인 사실이 필요하면 리프 노드(원본 청크)에서 정보를 검색 
● 전체적인 맥락이 필요하면 상위 요약 노드에서 정보를 검색 
3. 생성 (Generation):  검색된 다양한 층위의 정보를 조합하여 LLM이 최종 답변을 생성함 
20 RAPTOR (Sarthi et al, 2024) 07 Advanced RAG (2) 
전체 맥락 
구체적인 사실 
Xu, Rongwu, et al. "Knowledge conflicts for llms: A survey." arXiv preprint arXiv:2403.08319  (2024). 
 → 긴 문서를 처리하는 데 유용함 
21 Knowledge Conﬂict 02
지식 충돌 
22 RAG는 완벽할까? 
07 Advanced RAG (2) 
Knowledge Conﬂict (지식 충돌) 
LLM의 내부 지식(Parametric Knowledge)과 외부 지식(External Knowledge, e.g. RAG), 또는 이들 내부에서 서로 다른 정보가 
상충하는 현상 
● 관련 개념: 
● Parametric 지식 (Memory) : LLM이 학습을 통해 내부에 저장하고 있는 지식 
● Non-parametric 지식 (Context) : 그 외 모든 외부 정보 
● 모델이 충돌하는 정보 중 어떤 것을 '신뢰(Trust)'하고 '선택(Selection)'할 것인지가 핵심 과제 
● 예: 모델은 'A는 생존해 있다'고 아는데, 뉴스는 'A 사망'인 경우 

지식 충돌의 유형 
1. 내부 지식 vs 외부 지식 (Context-Memory Conﬂict) 
2. 외부 지식 간의 충돌 (Inter-Context Conﬂict) 
3. 내부 지식 내 충돌 (Intra-Memory Conﬂict) 
23 Knowledge Conﬂict 07 Advanced RAG (2) 
!

내부 지식 vs. 외부 지식 
● 모델이 이미 알고 있는 지식(Internal Memory)과 검색해온 문서(Context)가 충돌하는 경우 
● 예: 모델은 'A는 생존해 있다'고 아는데, 뉴스는 'A 사망'인 경우 
● 모델은 자신의 내부 지식이 강력할수록(Conﬁdence가 높을수록) 외부 문서를 무시하고 내부 지식을 따르는 경향이 있음. 
● 모델에게 "문서의 내용에만 충실히 답하라"는 강력한 시스템 프롬프트가 없을 경우, 모델은 익숙한 정보를 선택함 
● 다만 문맥이 논리적이고, 일관적이며, 설득력 있다면 문맥을 더 신뢰함 
● 모델이 어느 쪽을 우선할지에 대한 절대적인 규칙은 없으나, 정보의 품질과 구조가 선택에 큰 영향을 미침 
24 Context-Memory Conﬂict 07 Advanced RAG (2) 
이탈리아 는 월드컵 역사상 가장 성공적인  
국가대표팀으로, 
1934년, 1938년, 1982년, 2006년 까지 총 4회 
우승 을 차지했다. 
독일 은 공식적으로  
자신들이 월드컵  
역사상 가장 성공적인  
국가대표팀 이라는  
타이틀을  
주장해왔다… 
FIFA 월드컵에서 가장 많은 우승을 차지한 팀은 어디인가? 
Xu, Rongwu, et al. "Knowledge conflicts for llms: A survey." arXiv preprint arXiv:2403.08319  (2024). 

25 Context-Memory Conﬂict 07 Advanced RAG (2) 
LLM이 오답인 예시 
● Question : Google DeepMind의 수석 과학자(Chief Scientist) 는 누구인가? 
● 파라미터 지식 (LLM) : Google DeepMind의 현재 수석 과학자는 데미스 하사비스(Demis Hassabis) 이다. 그는 2010년에 
DeepMind를 공동 창업했으며, 이후 연구를 이끌어왔다. 
● 외부 지식 (Google) : DeepMind는 Google의 Brain 팀과 통합되어 Google DeepMind로 재편되었으며, 제프 딘(Jeﬀ Dean) 이 
Google DeepMind의 수석 과학자 역할을 맡게 되었다. 
● cf ) 데미스 하사비스( Demis Hassabis): 수석 과학자 (X), CEO (O)

원인1. Temporal misalignment 
● 과거 데이터로 학습된 모델이 최신 정보나 변화된 현실을 반영하지 못함 (외부 문맥에 정답이 있는 경우) 
● 기존 대응법의 한계: 
● 지식 편집 (Knowledge Editing): 기존 모델의 파라미터를 직접 수정해 특정 지식을 업데이트 
→ 업데이트 시 모델 내부 일관성 파괴 및 할루시네이션 유발 가능 
● RAG:  외부 데이터베이스나 웹 문서를 검색해 모델의 출력을 보완 
→ 파라미터를 수정하지 않으므로 외부 지식과 내부 지식의 충돌이 필연적임 
● Continual Learning (CL):  새로운 데이터로 모델을 계속 재학습 
→ 치명적 망각(Catastrophic Forgetting) 및 막대한 계산 비용 
26 Context-Memory Conﬂict 07 Advanced RAG (2) 
RAG 
새로운 데이터 
❌

원인2. Misinformation Pollution 
● 잘못된 정보가 컨텍스트에 유입되어 모델의 기존 기억과 충돌하는 현상 (모델 내부에 정답이 있는 경우) 
● 잘못되거나 악의적으로 조작된 정보가 컨텍스트로 주어진 경우 
● 프롬프트 인젝션 (Prompt Injection): 사용자 입력을 통한 악의적 정보 주입 
● Sycophancy (아첨 현상):  모델이 진실보다 사용자의 의견에 동조하려는 경향 
● 문제점: 모델이 무비판적으로 문맥을 수용할 경우 오정보를 확산시키는 도구가 됨 
27 Context-Memory Conﬂict 07 Advanced RAG (2) 

해결책: 문맥 우선 vs. 메모리 우선 
● Faithful to Context (문맥 우선): 
● RAG 등에서 주어진 정보를 최대한 정확히 반영하려는 경우 
● Discriminating Misinformation 오정보 식별 (메모리 우선): 
● 외부 정보가 의심스러울 때 내부 파라미터 지식(메모리)에 충실해야 함 
28 Context-Memory Conﬂict 07 Advanced RAG (2) 

해결책: 문맥 우선 vs. 메모리 우선 
● 문맥 우선 전략: 
● KAFT : 내부 지식과 정반대되는 가짜 문맥을 일부러 보여주고 문맥을 따르도록 모델을 훈련시키는 방식 
● CAD : 모델이 자기 생각으로 말할 때와 문맥을 보고 말할 때의 차이를 비교해서, 오직 문맥 때문에 높아진 
단어만 골라 답변하도록 하는 방식 
● 메모리 우선 전략: 
● 비판적 프롬프팅 (Vigilant prompting): "문서에 오류가 있을 수 있음"을 경고하는 시스템 프롬프트를 주는 방식 
● 훈련된 판별기 (Discriminator) 사용: 정보의 신뢰도를 판별하는 별도의 소형 모델을 훈련시켜 가짜 뉴스를 사전에 차단 
29 Context-Memory Conﬂict 07 Advanced RAG (2) 

그 외: 출처 분리 및 사실성 개선 
● Disentangling Sources (출처 분리): 
● "내부 지식에 따르면 A, 외부 문맥에 따르면 B"라고 나누어 답변하는 방식 
● Improving Factuality (사실성 개선): 
● 내부와 외부 지식 중 더 진실에 가까운 정보를 결합하거나 선택하여 최종 답변의 
정확도를 극대화하는 방식 
30 Context-Memory Conﬂict 07 Advanced RAG (2) 

외부 지식 간 충돌 
● 외부 소스(RAG, 웹 검색 등)에서 가져온 여러 문서들이 서로 상충하는 정보를 포함하고 있는 상태 
● 예) 문서 A: "가격 100원" , 문서 B: "가격 120원" 
● 발생 시나리오: 
● Entity Ambiguity:  동명이인이나 유사한 명칭의 정보를 섞어 가져온 경우 
● Information Density:  문서 A는 부분적인 정보를, 문서 B는 전체적인 정보를 담고 있어 충돌하는 것처럼 보임 
● Temporal Variation:  2023년 기사와 2024년 기사가 동시에 검색되어 수치가 다른 경우 
● 이때 모델이 어떻게 다수결을 따르거나 신뢰도를 평가할지가 핵심 
● 대부분의 LLM은 '다수결(Majority Vote)'  혹은 '문서 순서(Position Bias)' 에 의존하는 취약점을 보임 
31 Inter-Context Conﬂict 07 Advanced RAG (2) 
!
"이 식당 정보를 찾으려고 블로그 3개를 봤는데, 하나는 월요일 
휴무, 하나는 화요일 휴무, 하나는 연중무휴라고 하네? 어떤 
블로그가 진짜지?" 
해결책 
● 특화 모델 활용:  문장 간 모순을 찾아내는 전용 모델(PCNN 등)을 사용하여 충돌 확률이 높은 문서를 사전에 필터링 
● 외부 도구 연동:  LLM 혼자 고민하게 두지 않고, 구글 검색, 학술 자료 검색(Scholar), 파이썬 코드 실행기 등을 '외부 검증 도구'로 
활용해 사실 여부를 교차 검증함 
32 Inter-Context Conﬂict 07 Advanced RAG (2) 

33 그 외 추가적인 기법들 07 Advanced RAG (2) 
다양한 방향으로 방법론들이 진화중 
1. Agentic AI 방식으로 진화된 RAG 방향의 연구 
2. Knowledge Conﬂict 방향에서 어떠한 지식을 믿고 따를지 동적으로 결정하는 연구 
3. Attribution and Faithfulness 연구: 답변이 정말 근거 문서에 의해 지지되는지 평가하고 강제하는 연구, 근거 없는 문장은 
생성하지 않게 만들거나, 생성 후에 근거 검증 단계로 걸러내는 방향 
4. Memory and Personalization: 대화 맥락과 사용자 선호를 장기 메모리로 유지하면서 검색을 개인화하는 방향 

34 07 Advanced RAG (2) 
● GraphRAG: 문서를 단순히 검색하지 않고 연결된 지식 그래프로 구성해, 질문에 필요한 관계까지 함께 추론하는 RAG 방식 
● Modular RAG: Agentic AI 개념과 유사하게 여러 개의 ʻ빌딩 블록' 또는 모듈이 서로 상호작용하여 검색 및 응답 생성 과정을 
최적화하는 RAG 방식 
● Knowledge Conﬂict: LLM의 내부 지식(Parametric Knowledge)과 외부 지식(External Knowledge) 또는 이들 내부에서 서로 
다른 정보가 상충하는 현상 
Summary 
www.upstage.ai © 2025 Upstage Co., Ltd. 

