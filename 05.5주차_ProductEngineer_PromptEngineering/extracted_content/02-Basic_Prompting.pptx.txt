[02강] Basic Prompting & 
Tutorial 
이화여자대학교 인공지능학과 조교수 © 2025 Upstage Co., Ltd. 조현수 
2 저작권 안내 
 
(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은 
운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다. 
콘텐츠 일부 또는 전부를 복사, 복제, 판매, 재판매 공개, 공유 등을 할 수 없습니다. 
유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다. 
유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다. 
•콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위 
•콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위 
•콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위 
•콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위 
•지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위 
•다른 정보와 결합하여 Upstage Education의 콘텐츠임을 알아볼 수 있는 저작물을 작성, 공개하는 행위 
•제공된 데이터의 일부 혹은 전부를 Upstage Education 프로젝트/실습 수행 이외의 목적으로 사용하는 행위 
3 강의 목표 
학습 목표 
•Prompt Engineering의 기본 구조를 이해한다. 
•Persona Injection과 In-context Learning 기법을 활용할 수 있다. 
•API 환경에서 프롬프트 설계 및 실험을 수행한다. 

4 01.Basic Prompting 
(1) Persona Injection 
(2) In-context Learning 
02. Tutorial 
(1) Tutorial 목차 
5 Basic Prompting 01
정교한 답변 유도를 위한 프롬프팅 전략 
6 [Recap] Prompt 
AI와의 대화: 프롬프트 
프롬프트란? 
연극에서 대사나 동작을 지시하고 상기시켜 주는 일이나 말 또는 행위로 무대 위 연기가 원활히 진행되도록 행동을 유도 하고 방향을 
제시하는 역할 
Prompter 02 Basic Prompting & Tutorial 
7 Large Language Models 
AI와의 대화: 프롬프트 
LLM 관점에서의 프롬프트 
LLM에 들어가는 입력되는 모든 텍스트를 의미(역할, 정보, 예시 등의 사용자가 기재한 모든 구성요소) 
“나 제주도 갈건데, 2박 3일 여행 코스 짜줘. 운전은 잘 못하고 맛집 돌아다니는 거 좋아해. 
예산은 50만원 이내로하고 엑셀 형식으로 정리해줘”  
User LLM 
Prompt 
01 Introduction 
8 Large Language Models 
AI와의 대화: 프롬프트 
LLM 관점에서의 프롬프트 
LLM에 들어가는 입력되는 모든 텍스트를 의미(역할, 정보, 예시 등의 사용자가 기재한 모든 구성요소) 
“나 제주도 갈건데, 2박 3일 여행 코스 짜줘. 운전은 잘 못하고 맛집 돌아다니는 거 좋아해. 
예산은 50만원 이내로하고 엑셀 형식으로 정리해줘”  
User LLM 
Prompt 
01 Introduction 
사실 프롬프트는 사용자가 기재한 요소로만 
구성되어있지는 않음 
Prompt → 사실 구성이 두 개임 
시스템 프롬프트 vs 인풋 프롬프트 
•시스템 프롬프트: AI에서 응답 시 반드시 지켜야할 최상위 레벨의 명령어 집합. 제약 조건, 개인 정보, 출력 형식 등 모델의 근본적인 
행동 양식을 설정하여 사용자의 눈에는 보이지 않지만 , 대화가 시작되는 순간부터 끝날 때까지 모델의 모든 사고 과정 밑바탕에  
깔려있는 고정된 컨텍스트 
•인풋 프롬프트: 사용자가 AI에게 당장 해결하기 바라는 질문 , 명령 또는 데이터를 포함하는 즉각적이고 가변적인 요청 메시지. 
02 Basic Prompting & Tutorial 

10 Basic Prompting 
Prompt의 구성 요소 
크게 두 가지로 구분 
•Role:  모델이 어떤 관점과 정체성에서 답변하는지 정의 
a. System: 모델의 행동 규칙, 역할, 출력 스타일 정의 (전역 지침) 
b. User: 실제 요청, 업무 지시, 입력 
c. Assistant: 이전 모델 응답, 대화 이력 유지 
•Instruction/Content:  모델이 수행할 구체적인 행동 
각 요소 별로 예시나 역할, 지시사항에 대해 자유롭게 작성 가능 
02 Basic Prompting & Tutorial 
11 Persona Strategies 
Persona Injection 
LLM에 대해서 역할(role)을 부여하는 것. 출력 스타일과 관점 제어에 도움. 
•Role Prompting: "너는 20년 차 시니어 개발자야" 등 역할 부여. 
•Emotional Prompting: 감정적인 호소나 동기 부여를 통해 답변의 품질을 미세 조정 
(예: "이건 내 커리어에 정말 중요한 일이야"). 
[페르소나 주입] 
당신은 법률 문서 분석을 수행하는 
보조 AI 입니다. 시스템 프롬프트 (System Prompt) 
역할 및 맥락 정의 
사용자 프롬프트 (User Prompt) 
다음 계약서를 핵심 조항 위주로 요약해줘. AI 응답 (Assistant Response) 
계약서 요약은 다음과 같습니다. 
02 Basic Prompting & Tutorial 
12 Persona Strategies - Paper(1) 
ExpertPrompting: Instructing Large Language Models to be Distinguished Experts 
단순히 역할 이름만 주는 것이 아닌, 그 전문가가  어떻게 행동하는지 까지 구체적으로 묘사하여 성능을 극대화 
ex. 의사처럼 답해 → 의사라면 어떤 전문 용어를 쓰고, 어떤 관점으로 환자를 보는지 분석한 내용을 함께 넣어서 전문가 답변을 얻음 
[1] Xu et al., "ExpertPrompting: Instructing Large Language Models to be Distinguished Experts" , arXiv, 2023. 
기본 프롬프트: 
원자의 구조를 설명해 주세요. Expert Identity 
당신은 원자 구조와 원자 수준의 물질 특성을 전문으로 하는 
물리학자입니다.  원자의 구성과 구조에 대한 이해하고 있으며 
…
 에너지 수준에서 원자의 거동에 미치는 영향에 대해 깊이 
이해하고 있습니다. 기본적인 사실을 
나열하는 수준의 설명 
전문 용어를 사용하고, 원자의 거동을 
지배하는 힘에 대한 설명까지 포함하여 
훨씬 더 깊이 있고 전문적인 설명 
 
 물리학과 관련된 전문 지식을 갖추고 어떤 정보를 
이해하고 있는지, 전문가라면 어떻게 
행동하는지까지 구체적으로 묘사 풀어야 할 문제 전달 
실제 결과 02 Basic Prompting & Tutorial 
13 Persona Strategies - Paper(2) 
Encouraging divergent thinking in large language models through multi-agent debate. 
여러 명의 AI 토론자와 심판을 등장시켜 가상의 토론장을 구성 
이 과정에서 서로 반박하고 주장을 강화하며 더 나은 결론에 도달하도록 유도 
[5] Liang, Tian, et al. "Encouraging divergent thinking in large language models through multi-agent debate." Proceedings of the 2024 conference on empirical methods 
in natural language processing. 2024. [메타 프롬프트] 
당신은 토론자입니다. 토론 대회에 오신 
것을 환영합니다. 우리의 목표는 정답을  
찾는 것이므로, 서로의 관점에 완전히  
동의할 필요는 없습니다. 토론 주제는 
다음과 같습니다: 
<토론 주제> [찬성 측 토론자 프롬프트] 
   
당신은 찬성 측입니다. 자신의 관점을 
제시해 주세요. [반대 측 토론자 프롬프트] 
   
당신은 반대 측입니다. 찬성 측의 주장에 
동의하지 않습니다. 그에 대한 이유와 
당신의 답변을 제시해 주세요. 
[판사 프롬프트] 
   
당신은 사회자입니다. 토론 대회에는 두 명의 토론자가 참여합니다. 이들은 <토론 주제>에 
대해 자신의 답변을 제시하고 각자의 관점을 논의할 것입니다. 각 라운드가 끝날 때마다, 
당신은 양측의 답변을 평가하고 어느 쪽이 올바른지 결정해야 합니다. 
02 Basic Prompting & Tutorial 
14 Persona Strategies - Paper(2) 
Encouraging divergent thinking in large language models through multi-agent debate. 
GPT-3.5-Turbo + MAD: GPT-3.5-Turbo에 MAD(Multi-Agent Debate) 프레임워크를 적용했을 때, 모든 평가 지표(COMET , 
BLEURT , HUMAN)에서 성능이 크게 향상 
[5] Liang, Tian, et al. "Encouraging divergent thinking in large language models through multi-agent debate." Proceedings of the 2024 conference on empirical methods 
in natural language processing. 2024. 
 
 02 Basic Prompting & Tutorial 
15 In-Context Learning 
Intuition 
인간은 낯선 문제를 마주했을 때, 참고할 예시나 선례가 있으면 훨씬 수월하게 문제를 해결할 수 있음 . 이는 과거의 경험이나 지식을 현재의 
상황에 적용하여 해결책을 유추하는 과정과 유사함 
LLM 역시 방대한 데이터를 학습했지만, 모든 문제를 완벽하게 해결할 수는 없음. 
인간이 예시를 참고하듯이, 모델에게도 문제 해결의 실마리가 될 수 있는 문맥 또는 예시를 제공하면 성능을 향상시킬 수 있지 않을까? 
02 Basic Prompting & Tutorial 
16 In-Context Learning 
In-Context Learning이란? 
사전 학습된 언어 모델에 대해서, 모델 파라미터를 전혀 수정하지 않은 상태에서 프롬프트 내에 주어진 문맥과 예시들 사이의 패턴을 
즉석에서 참고하여 새로운 작업을 수행하는 능력 
 “말로 설명하기 어려운 복잡한 지시사항, 뉘앙스를 예시를 통해 단번에 이해” 
주어진 프롬프트 내 예시와 패턴을 일시적으로 활용하는 것으로 결과가 모델 가중치, 모델 내부에 저장되지 않음. 
→ 입력이 바뀌면 효과도 즉시 사라짐 
시스템 프롬프트 (System Prompt) 
당신은 유용한 AI 어시스턴트입니다. 
(기본 역할 정의) 
사용자 프롬프트 (User Prompt) 
요청: 다음 계약서를 핵심 조항 위주로 요약해줘. AI 응답 (Assistant Response) 
계약서 요약은 다음과 같습니다. 
[예시 추가] 
입력: ʻ임대차 계약에서 보증금 반환 
의무는 누구에게 있나?’ 
출력: ʻ임대인’에게 있습니다. 02 Basic Prompting & Tutorial 
17 In-Context Learning 
“Shot”의 개념 
프롬프트 내에 포함되는 입력과 이상적인 출력(정답) 쌍의 개수 
•문제와 정답이 하나의 세트로 구성되어야함 
•Shot = [Input: 모델이 처리해야할 텍스트 (질문) - Output: 모델이 내놓기를 기대하는 모범 답안 (정답)] 
Shot이 주어짐으로서 
•포맷 가이드: 답변을 단답형으로할지, 서술형으로할지 형식을 지정 
•추론 유도: 풀이 과정을 함께 예시로 주면 모델도 풀이 과정을 함께 작성하며 문제를 풀이 등을 유도할 수 있다. 02 Basic Prompting & Tutorial 
18 In-Context Learning 
Basic prompting (=Zero-shot prompting / Zero-shot Learning) 
예시 없이 오직 Instruction만으로 작업을 수행. ex. 번역, 요약 
•장점: 간결성, 간단, token 수 적음, 경제적 
•단점: 복잡한 작업에 대해 약함, 지시사항만으로 전달하기 어려운 작업은 정확히 묘사가 어려움 
입력(질문) 
포괄적인 전략 담은 지시사항 LLM 출력(전략 과정 포함) 02 Basic Prompting & Tutorial 
19 In-Context Learning 
In-Context Learning (=Few-shot Prompting / Few-shot Learning) 
Instruction과 함께 1~N개의 예시를 제공 (Input-Output 쌍) ex. ʻ감성 분석' , ʻ정규 표현식 추출' 등의 복잡한 작업에 대해서 주로 사용 
•장점: 정확도 및 성능 향상, Formatting에도 효과적 (output을 제시하고 있으므로 모델이 output 형식을 모방) 
•단점: zero-shot보다 많은 token 소모, 비용 증가 
입력 
예시 추가 
 
 작업: 리뷰에 대한 감정 분류 
 02 Basic Prompting & Tutorial 
20 In-Context Learning 
Few-shot Prompting의 설계 최적화 
예제 구성도 성능에 중요한 요소 - “무엇을, 어디에 배치할 것인가?” 
•선택 
•유사성 기반: 입력 질문과 의미적으로 가장 가까운 예제 선택 
•다양성 고려: 편향 방지를 위해 다양한 유형의 예제 포함 
“What Makes Good In-Context Examples for GPT-3?” 
- ICL 성능에 영향을 미치는 예시를 입력과 의미적으로 유사한 예시를 검색해서 사용할 때 랜덤 샘플링보다 월등히 좋은 성능을 보임을 입증 
•순서 
•최신성 편향: 모델은 프롬프트의 마지막 예제에 가장 큰 영향을 받으므로  중요한 예제를 끝부분에 배치하는 전략 
“Calibrate Before Use: Improving Few-Shot Performance of Language Models” 
- ʻRecency Bias’를 통해 마지막에 배치된 예시들의 레이블이 모델의 최종 결정에 영향을 미친다는 것을 증명 
[1] Reference: Liu et al. (2021), "What Makes Good In-Context Examples for GPT-3?" 
[2] Reference: Zhao, T . Z., et al. (2021). "Calibrate Before Use: Improving Few-Shot Performance of Language Models." ICML 2021. 02 Basic Prompting & Tutorial 
21 In-Context Learning 
Zero-shot vs Few-shot 
작은 모델의 경우 예제(shot)을 줘도 변화가 거의 없지만 모델이 클수록 예제를 주면 성능이 드라마틱하게 향상 
[1] Brown et al., "Language Models are Few-Shot Learners" , NeurIPS, 2020. 
Natural Language Prompt: 지시문이 함께 주어짐 
No Prompt: 지시문 없이 예제 패턴만 주어짐 02 Basic Prompting & Tutorial 
22 In-Context Learning 
In-Context Learning vs Traditional Fine-tuning 
Fine-tuning는 예시를 참고하며 파라미터를 업데이트하지만 
In-Context Learning은 파라미터 업데이트 과정 없이 예시를 반영한다는 점에서 추가적인 학습 비용이 필요하지 않음. 
[1] Brown et al., "Language Models are Few-Shot Learners" , NeurIPS, 2020. 
02 Basic Prompting & Tutorial 
23 In-Context Learning 
In-Context Learning 
장점 
•모델의 가중치를 업데이트하지 않으므로 이를 위한 자원, 시간이 필요없음 
•별도의 모델 필요없이 다양한 작업을 예시만 교체해주면 바로 수행 가능 
단점 
•예시를 전적으로 신뢰하므로 예시가 잘못된 경우 제대로된 작업 수행이 불가능. 또한 예시의 종류, 순서에 따라서 모델의 답변 품질이 
달라지기 때문에 엔지니어링에 대한 노력이 필요 
•모델이 한 번에 읽을 수 있는 글자 수의 한계 때문에 복잡거나 데이터 자체가 매우 긴 경우에는 적용하기 어려움 
02 Basic Prompting & Tutorial 
24 Tutorial 02
Temperature 파라미터 조정과 프롬프트 전략(ICL, Persona)을 적용 

25 Tutorial 소개 
특정 데이터셋에 대해 Basic Prompting 적용을 통한 성능 향상시키기 
Settings: Model-Solar Mini / Task-MMLU와 유사한 샘플 데이터 (Language=Korean) 
•MMLU(Massive Multitask Language Understanding)는 대규모 언어 모델의 기본적인 언어 이해 및 추론 능력을 평가하기 위한 
표준 벤치마크로 수학, 물리, 컴퓨터 과학, 법학, 의학, 철학 등 57개 전문 분야의 객관식 문제로 구성됨. 모델이 사전 지식과 추론을 
바탕으로 정답을 선택할 수 있는지에 대한 평가를 목적으로 함. 
[튜토리얼 코드 링크] https://colab.research.google.com/drive/1aYF2LB-Rw4cdWYizeBPN5Xyup6R_W-47 
예시) 
글루코스는 근육 세포로 어떻게 운반되는가? 
    A. GLUT4라고 불리는 단백질 운반체를 통해. 
    B. 인슐린의 존재 하에만. 
    C. 헥소키나아제를 통해. 
    D. 단일 탄수화물 산 운반체를 통해.        [정답: A] 02 Basic Prompting & Tutorial 
26 Tutorial(1) - MMLU 채점하기 
예시 문제에 대한 초기 Prompt 
02 Basic Prompting & Tutorial 
Questions) 글루코스는  근육 세포로  어떻게  운반되는가 ?
Choices) 
    A. GLUT4 라고 불리는  단백질  운반체를  통해.
    B. 인슐린의  존재 하에만 .
    C. 헥소키나아제를  통해.
    D. 단일 탄수화물  산 운반체를  통해.  
27 Tutorial(1) - MMLU 채점하기 
예시 문제 입력 시 모델의 답변 
정답은 맞지만 답변에 대한 형식을 지정해주지 않았으므로 채점을 자동화하기 어려움 (정답을 추출하기 어려움) 
→ 정답 추출을 위한 모델 답변 형식 지정 prompt 설정 
02 Basic Prompting & Tutorial 
28 Tutorial(1) - MMLU 채점하기 
Prompt에 조건 추가 (출력 형식 지정) 
format_mmlu_prompt를 이용해서 모델에 조건을 추가 
“Respond with only the letter (A, B, C, or D). ” 
02 Basic Prompting & Tutorial 
29 Tutorial(1) - MMLU 채점하기 
출력 형식 지정 시 모델의 답변 
모델의 답변에 대해서 가장 첫번째 알파벳을 이용해서( pred = response.strip ().upper ()[0])prediction을 parsing 
→ Prompt 한 줄로 모델의 출력 형식 조절이 가능, 그러나 한 단어로 출력하라는 지시사항을 명확하게 따르진 않음 
02 Basic Prompting & Tutorial 
30 Tutorial(2) - Zero-Shot vs Few-Shot 
Prompt에 예시를 추가 
답변을 어떻게 하는지 직접 모델에게 보여줌 
(이전에는 “Respond with only the letter. ” 만 추가) 
02 Basic Prompting & Tutorial 
31 Tutorial(2) - Zero-Shot vs Few-Shot 
Prompt에 예시를 추가 
각 prompt에 따른 모델의 출력 결과 
→ 지시 사항만 추가했을 때도 기존보단 답변을 형식에 맞춰서 진행하지만 예시를 보여주면 더 정확하게 사용자의 의도를 따를 수 있음 
<Zero-Shot> 
<Few-Shot> 02 Basic Prompting & Tutorial 
32 LLM에서의 Temperature 
Temperature는 확률 분포(softmax를 통해 나온 확률값들의 분포)를 변형하여 모델이 안전한 선택을 할지 모험적인 선택을 할지 
결정하는 파라미터 
- Low Temperature (T < 1.0): 분포를 뾰족하게 만듦, 확률이 높은 단어가 선택될 확률을 더 극대화 (Deterministic) 
- High Temperature (T > 1.0): 분포를 평평하게 만듦, 확률이 낮은 단어가 선택될 확률을 높임 (Stochastic) 
Tutorial(3) - LLM Temperature: 무작위성 제어 
02 Basic Prompting & Tutorial 
33 Tutorial(3) - Temperature 조절 
Temperature 조절에 따른 답변의 변화 
T=0일 때, 가장 확률이 높은 토큰만 선택 / 출력이 매우 결정적 → 출력 변화 없음 
T=1일 때,  모델이 학습한 확률 분포를 그대로 사용 / 어느 정도 무작위성을 가짐 → 출력마다 결과 다름 
<T=0> <T=1> 02 Basic Prompting & Tutorial 
34 Tutorial(3) - Temperature 조절 
특정 문제에 대해 반복해서 답변했을 때의 결과 변화 
예시 문제, 보기, 정답 
Temperature 설정값 , 30 번 반복
(Solar model’s T ∈ [0, 2]) 
02 Basic Prompting & Tutorial 
35 Tutorial(3) - Temperature 조절 
예시 문제에 따른 답변 선택 횟수 변화 
각각 30번씩 반복했을 때 낮은 temperature에서는 30번 모두 같은 결과를 출력하지만, 
temperature가 커질 수록 다른 값을 출력하기도 함. (무작위성을 보임) 
02 Basic Prompting & Tutorial 
36 Summary 
Basic Prompting 
•Persona Injection 
•In-context Learning 
•Basic Prompting (=Zero-shot Prompting/ Zero-shot Learning) 
•In-context Learning (=Few-shot Prompting/ Fewo-shot Learning) 
•Tutorial 
[1] https://www.upstage.ai/blog/en/introducing-solar-mini-compact-yet-powerful 02 Basic Prompting & Tutorial 
www.upstage.ai © 2025 Upstage Co., Ltd. 

