from dataclasses import dataclass, field
from typing import List, Dict

@dataclass
class WeekDetail:
    week: str = ""
    files: List[str] = field(default_factory=list)
    tech_stack: List[str] = field(default_factory=list)
    learning_paragraphs: List[str] = field(default_factory=list)
    code_examples: Dict[str, str] = field(default_factory=dict)


def get_detail() -> WeekDetail:
    """01.1ì£¼ì°¨_AI Literacy: ìƒì„¸ í•™ìŠµ ê¸°ë¡ (í•œêµ­ì–´)
    
    AI/ML ê¸°ì´ˆ, Python í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM) í™œìš©
    """

    w = WeekDetail(week="01.1ì£¼ì°¨_AI_Literacy")

    w.files = [
        "00.ê°•ì˜ìë£Œ/AI_ê¸°ì´ˆ_ê°œë….pdf",
        "01.ê°•ì˜ìë£Œ/LLM_í”„ë¡¬í”„íŠ¸_ì—”ì§€ë‹ˆì–´ë§.pdf",
        "01.daily_mission/Day1_ê¸°ì´ˆê°œë….ipynb",
        "01.daily_mission/Day2_í”„ë¡¬í”„íŠ¸ë””ìì¸.ipynb",
        "01.daily_mission/Day3_ì‘ìš©ì‚¬ë¡€.ipynb",
        "02.advanced_mission/Day4_ì‹¬í™”í”„ë¡œì íŠ¸.ipynb",
        "02.advanced_mission/Day5_ìµœì í™”.ipynb",
    ]

    w.tech_stack = [
        "Python 3.9+",
        "LLM API: OpenAI GPT, Anthropic Claude",
        "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§: Zero-shot, Few-shot, Chain-of-Thought",
        "ë¼ì´ë¸ŒëŸ¬ë¦¬: LangChain, LlamaIndex",
        "ë°ì´í„° ì²˜ë¦¬: JSON, CSV, í…ìŠ¤íŠ¸ íŒŒì‹±",
    ]

    w.learning_paragraphs = [
        (
            "ğŸ“… Day 1: AIì™€ LLM ê¸°ì´ˆ ì´í•´\n"
            "- AI, Machine Learning, Deep Learningì˜ ê°œë… ë° ì°¨ì´ í•™ìŠµ\n"
            "- ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì˜ ë™ì‘ ì›ë¦¬ ì´í•´\n"
            "- í† í°(Token)ê³¼ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê°œë…\n"
            "- OpenAI API ê°€ì… ë° API í‚¤ ì„¤ì •\n"
            "- ì²« ë²ˆì§¸ API í˜¸ì¶œ (ChatGPTì™€ ëŒ€í™”í•˜ê¸°)"
        ),

        (
            "ğŸ“… Day 2: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ\n"
            "- í”„ë¡¬í”„íŠ¸ì˜ í•µì‹¬ 3ê°€ì§€: ì—­í• (Role), ì§€ì‹œì‚¬í•­(Instruction), ì˜ˆì œ(Example)\n"
            "- íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì›ì¹™\n"
            "- ì˜¨ë„(Temperature), ìµœëŒ€í† í°(Max Tokens) íŒŒë¼ë¯¸í„° ì¡°ì •\n"
            "- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ê³„\n"
            "- ë°˜ë³µì  í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤ìŠµ"
        ),

        (
            "ğŸ“… Day 3: ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²•\n"
            "- Few-shot Learning: ì˜ˆì œë¥¼ í†µí•œ í•™ìŠµ\n"
            "- Chain-of-Thought Prompting: ë‹¨ê³„ë³„ ì¶”ë¡  ìœ ë„\n"
            "- ë‹¤êµ­ì–´ í”„ë¡¬í”„íŠ¸ ì‘ì„± ë° ë²ˆì—­\n"
            "- êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜•ì‹ ì§€ì • (JSON, CSV)\n"
            "- ì˜¤ë¥˜ ì²˜ë¦¬ ë° ê²€ì¦ ë¡œì§"
        ),

        (
            "ğŸ“… Day 4: ì‹¬í™” í”„ë¡œì íŠ¸ - ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ\n"
            "- ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n"
            "- ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±\n"
            "- ì‘ë‹µ ê²€ì¦ ë° ì¬ì‹œë„ ë¡œì§\n"
            "- ë¹„ìš© ìµœì í™” (í† í° ì‚¬ìš©ëŸ‰ ì¶”ì )\n"
            "- ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ êµ¬í˜„ (Q&A ë´‡, ë¬¸ì„œ ë¶„ì„ ë“±)"
        ),

        (
            "ğŸ“… Day 5: ìµœì í™” ë° ë°°í¬\n"
            "- í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ ì •ì˜\n"
            "- A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ ë¹„êµ\n"
            "- ì‘ë‹µ ì‹œê°„ ë° ë¹„ìš© ìµœì í™”\n"
            "- ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„ ë° ê°œì„ \n"
            "- ì™„ì„±ëœ í”„ë¡œì íŠ¸ ìµœì¢… ê²€ì¦"
        ),
    ]

    w.code_examples = {}

    w.code_examples['01_basic_api_call.py'] = '''import openai

# Day 1: ì²« ë²ˆì§¸ OpenAI API í˜¸ì¶œ
openai.api_key = "sk-your-api-key-here"

def chat_with_gpt(prompt: str) -> str:
    """OpenAI APIë¥¼ ì´ìš©í•œ ê¸°ë³¸ ì±— í•¨ìˆ˜"""
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=500
    )
    return response['choices'][0]['message']['content']

# ì‚¬ìš© ì˜ˆì œ
result = chat_with_gpt("íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì˜ ì¥ì ì€?")
print(result)
'''

    w.code_examples['02_prompt_templates.py'] = '''# Day 2: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ê³„
import openai
from typing import Dict

class PromptTemplate:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, role: str, instruction: str, example: str = ""):
        self.role = role
        self.instruction = instruction
        self.example = example
    
    def build(self, user_input: str) -> str:
        """ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""# ì—­í•  (Role)
{self.role}

# ì§€ì‹œì‚¬í•­ (Instruction)
{self.instruction}

# ì˜ˆì œ (Example)
{self.example}

# ì‚¬ìš©ì ì…ë ¥ (User Input)
{user_input}
"""
        return prompt

# í…œí”Œë¦¿ ì‚¬ìš© ì˜ˆì œ
template = PromptTemplate(
    role="ë‹¹ì‹ ì€ Python ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
    instruction="ì£¼ì–´ì§„ ì½”ë“œë¥¼ ë¦¬ë·°í•˜ê³  ê°œì„ ì ì„ ì œì‹œí•˜ì„¸ìš”.",
    example="ì˜ˆ: # ë‚˜ìœ ì½”ë“œ\\nx = [1,2,3,4,5]\\n# ê°œì„ : Pythonicí•˜ê²Œ range() ì‚¬ìš©"
)

user_code = "for i in range(len(my_list)): print(my_list[i])"
final_prompt = template.build(user_code)

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": final_prompt}],
    temperature=0.5
)
print(response['choices'][0]['message']['content'])
'''

    w.code_examples['03_fewshot_learning.py'] = '''# Day 3: Few-Shot Learning ì˜ˆì œ
import openai

def few_shot_translator(text: str) -> str:
    """Few-shot learningì„ í†µí•œ ìë™ ë²ˆì—­"""
    
    prompt = """ë‹¹ì‹ ì€ í•œì˜ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.

# ì˜ˆì œ:
ì‚¬ìš©ì: "ì•ˆë…•í•˜ì„¸ìš”"
ì–´ì‹œìŠ¤í„´íŠ¸: "Hello"

ì‚¬ìš©ì: "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤"
ì–´ì‹œìŠ¤í„´íŠ¸: "The weather is nice today"

ì‚¬ìš©ì: "ê°ì‚¬í•©ë‹ˆë‹¤"
ì–´ì‹œìŠ¤í„´íŠ¸: "Thank you"

# ì´ì œ ë‹¤ìŒì„ ë²ˆì—­í•˜ì„¸ìš”:
ì‚¬ìš©ì: "{}"
ì–´ì‹œìŠ¤í„´íŠ¸: """.format(text)
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response['choices'][0]['message']['content']

# Chain-of-Thought ì˜ˆì œ
def reasoning_math(problem: str) -> str:
    """ë‹¨ê³„ë³„ ìˆ˜í•™ ë¬¸ì œ í’€ì´ (Chain-of-Thought)"""
    
    prompt = f"""ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ì–´ì£¼ì„¸ìš”.

ì˜ˆì‹œ:
ë¬¸ì œ: 10 + 20 * 2ëŠ”?
ë‹µë³€:
1ë‹¨ê³„: ì—°ì‚°ì ìš°ì„ ìˆœìœ„ í™•ì¸ (ê³±ì…ˆì´ ë§ì…ˆë³´ë‹¤ ë¨¼ì €)
2ë‹¨ê³„: 20 * 2 = 40 ê³„ì‚°
3ë‹¨ê³„: 10 + 40 = 50
ìµœì¢… ë‹µ: 50

ì´ì œ ë‹¤ìŒ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”:
{problem}"""
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response['choices'][0]['message']['content']

# ì‚¬ìš© ì˜ˆì œ
print(few_shot_translator("í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤"))
print(reasoning_math("12 + 8 * 3 - 5ëŠ”?"))
'''

    w.code_examples['04_multiturn_conversation.py'] = '''# Day 4: ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ
import openai
from typing import List, Dict

class ConversationManager:
    """ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ê³  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, system_message: str):
        self.messages = [
            {"role": "system", "content": system_message}
        ]
        self.token_count = 0
    
    def add_user_message(self, content: str) -> None:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({"role": "user", "content": content})
    
    def get_response(self) -> str:
        """LLM ì‘ë‹µ ìƒì„±"""
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=self.messages,
                temperature=0.7,
                max_tokens=500
            )
            assistant_message = response['choices'][0]['message']['content']
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.messages.append({
                "role": "assistant",
                "content": assistant_message
            })
            
            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
            self.token_count += response['usage']['total_tokens']
            
            return assistant_message
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½ ì •ë³´"""
        return {
            "total_messages": len(self.messages) - 1,
            "total_tokens_used": self.token_count,
            "estimated_cost_usd": self.token_count * 0.00002
        }

# ì‚¬ìš© ì˜ˆì œ: íŒŒì´ì¬ íŠœí„°
tutor = ConversationManager(
    system_message="ë‹¹ì‹ ì€ ì¹œì ˆí•œ íŒŒì´ì¬ íŠœí„°ì…ë‹ˆë‹¤. ì´ˆë³´ì ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
)

tutor.add_user_message("íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ê°€ ë­ì˜ˆìš”?")
print("ì–´ì‹œìŠ¤í„´íŠ¸:", tutor.get_response())

tutor.add_user_message("ê·¸ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•  ìˆ˜ ì—†ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?")
print("ì–´ì‹œìŠ¤í„´íŠ¸:", tutor.get_response())

print("\\nëŒ€í™” ìš”ì•½:")
for key, value in tutor.get_conversation_summary().items():
    print(f"  {key}: {value}")
'''

    w.code_examples['05_optimization.py'] = '''# Day 5: í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ë¹„ìš© ê´€ë¦¬
import openai
import json
from datetime import datetime

class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ìµœì í™”í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = []
    
    def test_prompts(self, prompts: dict, test_input: str) -> None:
        """ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ì„±ëŠ¥ ë¹„êµ"""
        for name, prompt_template in prompts.items():
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": prompt_template.format(test_input)}],
                    temperature=0.5
                )
                
                result = {
                    "prompt_name": name,
                    "input": test_input,
                    "output": response['choices'][0]['message']['content'],
                    "tokens_used": response['usage']['total_tokens'],
                    "cost_usd": response['usage']['total_tokens'] * 0.00002,
                    "timestamp": datetime.now().isoformat()
                }
                self.results.append(result)
                
                print(f"âœ“ {name}: {result['tokens_used']} tokens")
            except Exception as e:
                print(f"âœ— {name}: {str(e)}")
    
    def get_best_prompt(self, metric: str = "tokens_used") -> dict:
        """ê°€ì¥ íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸ ì°¾ê¸°"""
        if not self.results:
            return None
        return min(self.results, key=lambda x: x[metric])
    
    def export_results(self, filename: str) -> None:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

# í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤ìŠµ
prompts = {
    "verbose": "ë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”: {}",
    "concise": "ì´ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”: {}",
    "structured": "ë‹¤ìŒì— ëŒ€í•´ 3ê°€ì§€ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë‚˜ì—´í•˜ì„¸ìš”: {}"
}

optimizer = PromptOptimizer()
test_text = "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ LLMì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤."

optimizer.test_prompts(prompts, test_text)

print("\\nìµœì ì˜ í”„ë¡¬í”„íŠ¸:")
best = optimizer.get_best_prompt()
if best:
    print(f"  ì´ë¦„: {best['prompt_name']}")
    print(f"  í† í°: {best['tokens_used']}")
    print(f"  ë¹„ìš©: ${best['cost_usd']:.4f}")

optimizer.export_results("prompt_optimization_results.json")
'''

    return w


def print_detail():
    d = get_detail()
    print(f"Week: {d.week}")
    print(f"Files: {len(d.files)} files")
    print(f"Tech Stack: {len(d.tech_stack)} technologies")
    print(f"Learning Content: {len(d.learning_paragraphs)} days")
    print(f"Code Examples: {len(d.code_examples)} examples")
