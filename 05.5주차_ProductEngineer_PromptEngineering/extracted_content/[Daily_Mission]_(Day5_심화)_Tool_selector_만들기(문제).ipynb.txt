# 🔍[Daily Mission] Day 5 - 심화 미션 — Tool Selector 만들기

## 미션 소개

지금까지 우리는 LLM을 사용해:
- 질문을 던지고
- 답변을 생성하며
- 그 결과를 평가해왔습니다.

하지만 실제로 LLM이 활용되는 많은 시스템에서는 모델이 **바로 답을 생성하지 않는 경우**가 더 많습니다.

대신 모델은 먼저 이런 판단을 해야 합니다.

> ❓ 이 질문은 계산이 필요한가?  
> ❓ 외부 정보를 가져와야 하는가?  
> ❓ 아니면 그냥 대화로 처리하면 되는가?

이처럼 **상황에 따라 행동을 선택하는 능력**이 바로 Agentic AI의 핵심입니다.

## 심화 미션의 목표

이번 심화 미션에서는 LLM이 사용자의 질문을 보고 **적절한 도구를 선택하는 역할**을 수행하도록 합니다.

즉, LLM은:
- 질문에 바로 답하지 않고
- 미리 정의된 도구 목록 중 하나를 선택하며
- 그 결과를 구조화된 형식(JSON)으로 출력합니다.

이것이 바로 도구 선택기입니다.

---
## 왜 이 미션이 중요한가?

이 미션이 중요한 이유는 다음과 같습니다.

- LLM을 단순한 “답변 생성기”가 아니라 **판단과 의사결정을 수행하는 컴포넌트**로 사용해볼 수 있습니다.
- System Prompt를 통해 모델의 역할과 제약을 명확히 정의하는 방법을 학습합니다.
- 실제 Agent 시스템에서 필수적인 **Routing / Tool Selection 구조**를 직접 구현합니다.


## 미션 개요 (Mission Overview)

이번 심화 미션에서는 LLM이 사용자의 질문을 분석하고, **어떤 도구를 사용해야 할지 스스로 판단하는 AI 에이전트**를 구현합니다.

1. **문제 상황 이해**  
사용자의 질문은 수학 문제, 정보 요청, 일반 대화 등 다양한 형태로 주어집니다. 에이전트는 질문의 유형을 파악한 뒤, 바로 답하지 않고 **적절한 도구를 선택하는 역할**을 수행합니다.

2. **도구 정의**  
에이전트가 선택할 수 있는 도구는 여러 종류가 있습니다. 수학 계산을 위한 `calculator`, 날씨 정보를 위한 `weather_api`, 그리고 도구가 필요 없는 경우의 `chat`입니다.

3. **System Prompt 설계**  
LLM이 도구 선택기 역할을 수행하도록 System Prompt를 통해 역할과 제약을 명확히 정의합니다. 특히 출력 형식을 JSON으로 제한해, 후속 처리에 사용할 수 있도록 합니다.

4. **Tool Selector 구현**  
사용자 질문과 System Prompt를 결합해 LLM이 하나의 도구를 선택하도록 합니다. 이 과정에서 LLM은 답변을 생성하지 않고, **판단 결과만 출력**합니다.

5. **출력 검증 및 테스트**  
모델의 출력이 올바른 JSON 형식인지, 정의된 도구 중 하나인지 확인합니다. 여러 유형의 질문을 입력해 에이전트가 올바른 선택을 하는지 점검합니다.

이번 미션은 LLM을 “대답하는 모델”이 아니라 **“무엇을 할지 결정하는 컴포넌트”로 사용하는 경험**을 제공하는 데 목적이 있습니다. 🚀


## 이번 미션에서 사용할 도구 정의

이번 미션에서 AI 에이전트는 사용자의 질문을 보고 **미리 정의된 도구 중 하나를 선택**합니다.

에이전트가 선택할 수 있는 도구는 다음 세 가지로 정의합니다.

---

**`calculator`**  
수학 계산이나 수치 연산이 필요한 질문에 사용합니다. 예를 들어, 덧셈·곱셈·비율 계산 등 정확한 계산 결과가 필요한 경우 이 도구를 선택합니다.

---

**`weather_api`**  
특정 지역의 날씨 정보를 묻는 질문에 사용합니다. 현재 날씨나 기온, 날씨 상태 등 외부 정보가 필요하다고 판단되는 경우 선택합니다.

---

**`chat`**  
계산이나 외부 정보 조회가 필요 없는 일반적인 대화나 설명 요청에 사용합니다. 도구를 사용할 필요가 없는 경우의 기본 선택지입니다.



## System Prompt 설계

이제 LLM이 **도구 선택기(Tool Selector)** 역할을 정확히 수행하도록 System Prompt를 설계합니다.

System Prompt는:
- LLM의 역할(Role)을 정의하고
- 무엇을 할 수 있고, 무엇을 하면 안 되는지 **행동 범위**를 제한하며
- 출력 형식을 **명확히 강제**하는 역할을 합니다.

---

### System Prompt에 포함되어야 할 핵심 요소

이번 미션의 System Prompt에는 다음 요소들이 반드시 포함됩니다.

1. **에이전트의 역할 명시**  
   - 질문을 분석해 도구를 선택한다

2. **사용 가능한 도구 목록 정의**  
   - calculator  
   - weather_api  
   - chat  

3. **출력 형식 제약**  
   - 반드시 JSON 형식으로 출력  -> tool을 잘 추출하기 위해
   - 자연어 설명이나 추가 텍스트 출력 금지

## 에이전트는 어떤 역할을 수행해야 할까?

이번 미션에서 사용하는 LLM은 사용자의 질문에대해 사용할 tool을 정의합니다.

- 질문을 분석하고
- 어떤 도구를 사용해야 할지 판단한 뒤
- 그 결과만을 출력하는 **도구 선택기** 역할을 수행합니다.

즉, 이 에이전트의 목적은 “무엇을 말할지”가 아니라 “무엇을 할지 결정하는 것”입니다.


### 원래 Agentic AI에서는 어떻게 할까?

실제 Agentic AI 시스템에서는 도구를 언제, 어떻게 사용할지에 대한 판단을 **학습을 통해 습득**하는 경우가 많습니다.

- 강화학습(RL)을 통해 도구 사용 정책을 학습하거나
- 과거 실행 결과를 바탕으로 판단을 개선하거나
- Planner / Executor 구조를 통해 다단계 의사결정을 수행합니다.
---

### 그럼 이번 미션에서는 왜 프롬프트만 사용할까?

이번 미션에서는 Agentic AI의 전체 복잡도를 다루기보다는, **핵심 개념인 ‘Routing(도구 선택)’에 집중**하기 위해 프롬프트 기반 방식으로 단순화합니다.

프롬프트를 사용하면:
- 별도의 학습 없이도
- LLM의 기존 언어 이해 능력을 활용해
- 도구 선택이라는 판단 과정을 직접 체험할 수 있습니다.

즉, 이번 미션은“Agentic AI의 입문 단계”로서 도구 선택이라는 개념을 가장 직관적인 방식으로 구현하는 것이 목표입니다.

### (Todo1) System Prompt를 코드로 정의하기

지금까지 배운 Prompt Engineering을 기반으로 어떻게하면 모델이 주어진 사용자 질문에 대해 필요한 도구를 잘 선택할지 system prompt를 설계해봅니다.

SYSTEM_PROMPT ="""
# ============================================
# TODO1: System Prompt 정의
# ============================================
당신은 질문을 분석하고
어떤 도구를 사용해야 할지 판단한 뒤
그 결과만을 출력하는 도구 선택기 역할을 수행합니다.
사용할 수 있는 도구는 calculator, weather_api, chat 3가지 입니다.
자연어 설명이나 추가 텍스트 출력 금지"""

import os
os.environ["UPSTAGE_API_KEY"] = "up_w8c0bYvkD7x9OUmUjJrzPlRv8GlLV"

import time
from openai import OpenAI

client = OpenAI(
    api_key=os.environ["UPSTAGE_API_KEY"],
    base_url="https://api.upstage.ai/v1"
)


def call_llm_api(system_prompt, user_prompt, model="solar-pro2"):
    """
    API Key를 사용해 단일 프롬프트에 대한 모델 응답을 반환
    """
    start_time = time.time()

    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": user_prompt
            }
        ],
        stream=False,
        temperature=0.0,
        max_tokens=256
    )

    elapsed_time = time.time() - start_time

    output_text = response.choices[0].message.content

    return output_text


def select_tool(user_query):
    """
    사용자 질문을 입력받아
    어떤 tool을 사용할지 LLM이 판단하도록 하는 함수
    """
    raw_response = call_llm_api(
        system_prompt=SYSTEM_PROMPT,
        user_prompt=user_query
    )
    return raw_response


import re

ALLOWED_TOOLS = {"calculator", "weather_api", "chat"}

def parse_and_validate_tool(response_text):
    """
    LLM 출력(자연어 포함)에서 tool 이름을 추출하고 검증
    """

    response_text = response_text.lower()

    for tool in ALLOWED_TOOLS:
        # 단어 단위로 tool 이름이 등장하는 지 확인
        if re.search(rf"\b{tool}\b", response_text):
            return tool

    raise ValueError(f"Could not determine tool from output: {response_text}")


### (Todo2) Parsing 함수 재정의
위에 정의된 parsing 함수는 단순히 모델의 출력에 대해 일치하는 Tool을 찾습니다.

이에 대해 더 정확하게 parsing할 수 있도록 전략을 세워 함수를 설계해보세요.

(System prompt에 출력 형식을 정의했다면, 해당 출력 형식을 이용해서도 tool을 추출할 수 있습니다.)

import re

ALLOWED_TOOLS = {"calculator", "weather_api", "chat"}

def parse_and_validate_tool(response_text):
    """
    LLM 출력(자연어 포함)에서 tool 이름을 추출하고 검증
    """
    # ============================================
    # TODO2: 도구 parsing 함수 정의
    # ============================================
    cleaned_text = response_text.lower().strip()
    for tool in ALLOWED_TOOLS:
        if tool in cleaned_text:
            return tool

    raise ValueError(f"Could not determine tool from output: {response_text}")


test_queries = [
    "What is 23 * 47?",
    "What's the weather like in Seoul today?",
    "Tell me a joke."
]

for query in test_queries:
    print(f"\nUser query: {query}")

    raw_output = select_tool(query)
    print("Raw LLM output:", raw_output)

    tool = parse_and_validate_tool(raw_output)
    print("🛠️ Selected tool:", tool)



### ❗️ 이 구조에서 가장 중요한 단계는 **정확한 tool을 고르는 것**이다. ❗️

Tool 선택이 잘못되면 아무리 실행 로직이 잘 설계되어 있어도 결과는 필연적으로 잘못될 수밖에 없다. 즉, tool 선택은 정확한 작업 수행을 위한 출발점이자 초석이다.

현재 구조는 **prompt 기반 판단에 의존**하고 있어 학습과 실험에는 적합하지만, 질문이 모호해질수록 오분류 가능성이 커지고 LLM의 표현 방식에 따라 판단이 흔들릴 수 있다는 한계가 있다.

>따라서 Agentic AI에서 중요한 학습 포인트는 tool 선택을 담당하는 모델이나 로직을 어떻게 설계하고 어떤 기준으로 routing 결정을 내릴 것인지 고민하는 것이다.


## (Todo3) Tool 선택 이후: Tool별 Prompt를 정의하고 실제 응답까지 생성하기

지금부터는

- LLM이 **어떤 tool을 사용할지 선택**한 이후
- 각 tool에 맞는 **전용 prompt를 미리 정의**해두고
- 선택된 tool에 따라 **실제 답변 생성까지 자동으로 수행**하도록 만든다

즉,  
> “tool 선택 → tool별 prompt 적용 → 최종 응답 생성”  
의 전체 파이프라인을 구성해본다.

# ============================================
# Todo3: Tool별 System Prompt 정의
# ============================================

TOOL_SYSTEM_PROMPTS = {
    "calculator": (
        """당신은 수학 계산 전문가입니다.
        사용자의 산술 연산 요청에 대해 단계별 풀이 과정과 최종 결과값을 정확하게 제공하세요.
        수식 외의 불필요한 서술은 최소화하고 숫자의 정확성에 집중하세요."""
    ),

    "weather_api": (
        """당신은 기상 정보 분석가입니다.
        특정 지역의 날씨, 기온, 습도 등 기상 관련 질문에 대해 최신 데이터를 기반으로 답변하세요.
        만약 구체적인 지역이 명시되지 않았다면 사용자에게 위치를 다시 물어보세요."""
    ),

    "chat": (
        """당신은 친절하고 유능한 AI 어시스턴트입니다.
        별도의 도구가 필요하지 않은 일상적인 대화나 일반적인 지식 질문에 대해 자연스럽고 풍부한 답변을 제공하세요.
        사용자의 기분을 파악하고 공감하는 태도를 유지하세요."""
    )
}

# ============================================
# Tool 실행 함수 (선택된 tool을 실제로 수행)
# ============================================

def run_tool(tool_name: str, user_query: str, model="solar-pro2"):
    """
    선택된 tool에 맞는 system prompt를 적용하여
    실제 LLM 응답을 생성한다.
    """

    if tool_name not in TOOL_SYSTEM_PROMPTS:
        raise ValueError(f"Unknown tool: {tool_name}")

    system_prompt = TOOL_SYSTEM_PROMPTS[tool_name]
    user_prompt = user_query

    response = call_llm_api(
        system_prompt=system_prompt,
        user_prompt=user_prompt,
        model=model
    )

    return response


## (Todo4) Tool 실행 전체 파이프라인

# ============================================
# Todo4: Tool 선택 → Tool 실행 전체 파이프라인에서
# test_queries를 더 다양하게 설정해보기
# ============================================

test_queries = [
    "What is 23 * 47?",
    "What's the weather like in Seoul today?",
    "Tell me a joke."
]

for query in test_queries:
    print(f"\n🗣️ User query: {query}")

    # 1. Tool 선택
    raw_output = select_tool(query)
    print("🤖 Raw LLM output:", raw_output)

    tool = parse_and_validate_tool(raw_output)
    print("[🛠️ Selected tool]:", tool)

    # 2. 선택된 Tool 실행
    answer = run_tool(tool, query)
    print("\n\n[🏁 Final answer]:", answer)
    print("------------------------------------")



### 위 셀을 통해 아래와 같은 행동이 가능
✔️ LLM이 판단하고 그에 걸맞는 답을 생성

✔️ System Prompt 하나로 Agent 역할 정의

✔️ 출력이 항상 기계가 처리 가능한 구조

✔️ Agentic AI의 핵심 구조(Routing) 체험


## (ToDo5) 새로운 도구 추가하기

현재 에이전트는 세 가지 도구만 선택할 수 있습니다.

- calculator
- weather_api
- chat

이번 ToDo에서는 사용자가 직접 **새로운 도구를 정의하고**, 에이전트가 해당 도구를 선택할 수 있도록 확장해봅니다.

예를 들어:
- `search`: 일반적인 정보 검색
- `translator`: 번역 작업
- `summarizer`: 긴 텍스트 요약
등의 도구를 추가할 수 있습니다. (자유롭게 설정)

도구를 추가하려면 다음을 수행해야 합니다.

1. 도구 이름과 역할을 정의한다
2. System Prompt에 새로운 도구를 추가한다
3. 테스트 질문을 만들어 올바르게 선택되는지 확인한다

---
위의 완성된 코드에 추가적인 tool을 구현해서 모델이 분별하고 알맞은 정답을 도출하는지 확인합니다.


## 미션 마무리

이번 미션에서는 LLM을 단순히 질문에 답하는 모델이 아니라, **“무엇을 해야 할지 판단하는 에이전트”로 사용하는 방법**을 단계적으로 구현해보았습니다.

---

### 이번 미션에서 우리가 한 것

- 사용자의 질문을 분석해 **어떤 도구를 사용할지 결정하는 Tool Selector**를 만들었습니다.
- System Prompt를 통해 에이전트의 역할과 행동 범위를 명확히 정의했습니다.
- 새로운 도구를 직접 추가하며, **에이전트가 확장 가능한 구조**임을 확인했습니다.

---

### 한계

이번 미션에서는 학습이나 강화학습 없이 **프롬프트 기반 방식**으로 에이전트를 구현했습니다.

실제 Agentic AI 시스템에서는:
- 학습된 정책(policy)
- 실행 결과를 반영한 개선
- 여러 도구를 순차적으로 사용하는 구조

등이 함께 사용됩니다.

이번 미션은 이러한 복잡한 구조로 나아가기 전, **Agentic AI의 입문 단계**를 경험하는 것이 목적이었습니다.


수고하셨습니다 🚀


###**콘텐츠 라이선스**
<font color='red'><b>**(주)업스테이지가 제공하는 모든 교육 콘텐츠의 지식재산권은
운영 주체인 (주)업스테이지 또는 해당 저작물의 적법한 관리자에게 귀속되어 있습니다.**</b></font>

콘텐츠 일부 또는 전부를 **복사, 복제, 판매, 재판매 공개, 공유** 등을 할 수 없습니다. 유출될 경우 지식재산권 침해에 대한 책임을 부담할 수 있습니다.

유출에 해당하여 금지되는 행위의 예시는 다음과 같습니다.
* 콘텐츠를 재가공하여 온/오프라인으로 공개하는 행위
* 콘텐츠의 일부 또는 전부를 이용하여 인쇄물을 만드는 행위
* 콘텐츠의 전부 또는 일부를 녹취 또는 녹화하거나 녹취록을 작성하는 행위
* 콘텐츠의 전부 또는 일부를 스크린 캡쳐하거나 카메라로 촬영하는 행위
* 지인을 포함한 제3자에게 콘텐츠의 일부 또는 전부를 공유하는 행위
* 다른 정보와 결합하여 Upstage Education의 콘텐츠임을 알아볼 수 있는 저작물을 작성, 공개하는 행위
* 제공된 데이터의 일부 혹은 전부를 Upstage Education 프로젝트/실습 수행 이외의 목적으로 사용하는 행위

