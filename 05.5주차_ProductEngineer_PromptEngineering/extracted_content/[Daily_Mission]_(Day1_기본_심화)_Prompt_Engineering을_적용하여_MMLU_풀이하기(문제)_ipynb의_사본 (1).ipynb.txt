# [Daily Mission] Day 1(ê¸°ë³¸) â€” MMLU ë°ì´í„° í™œìš©í•˜ê¸°

## ë¯¸ì…˜ ì†Œê°œ

ì´ë²ˆ Daily Missionì—ì„œëŠ” **LLM ì„±ëŠ¥ í‰ê°€ì˜ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ì¤‘ í•˜ë‚˜ì¸ MMLU ë°ì´í„°ì…‹**ì„ í™œìš©í•´ **SOLAR-mini ëª¨ë¸ì˜ Baseline ì„±ëŠ¥ì„ ì§ì ‘ ì¸¡ì •í•˜ëŠ” í‰ê°€ íŒŒì´í”„ë¼ì¸**ì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤.

ì´ë¥¼ í†µí•´ ë™ì¼í•œ MMLU í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ **ëª¨ë¸ì„ ì–´ë–»ê²Œ í‰ê°€í•´ì•¼ í•˜ëŠ”ì§€**ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ LLMì˜ ì„±ëŠ¥ì€ â€œì˜ ëŒ€ë‹µí•˜ëŠ” ê²ƒ ê°™ë‹¤â€ë¼ëŠ” ê°ê°ì ì¸ í‰ê°€ì— ì˜ì¡´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹¤ì œ ì—°êµ¬ë‚˜ ì‹¤ë¬´ì—ì„œëŠ” ì •ëŸ‰ì ì¸ ê¸°ì¤€(ë²¤ì¹˜ë§ˆí¬)ì„ í†µí•´ ëª¨ë¸ì„ ë¹„êµí•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.

ì´ë²ˆ ë¯¸ì…˜ì˜ ëª©í‘œëŠ” **ì ìˆ˜ ìì²´ê°€ ì•„ë‹ˆë¼**,  
> ğŸ‘‰ *â€œLLMì„ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠ”ê°€?â€*  
> ğŸ‘‰ *â€œí‰ê°€ë¥¼ ì½”ë“œë¡œ ì–´ë–»ê²Œ êµ¬í˜„í•˜ëŠ”ê°€?â€*  
ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

---

## ì´ë²ˆ ë¯¸ì…˜ì—ì„œ ë‹¤ë£° ë‚´ìš©

ì´ë²ˆ ë¯¸ì…˜ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ íë¦„ì„ ë”°ë¼ê°‘ë‹ˆë‹¤.

1. **MMLUë€ ë¬´ì—‡ì¸ì§€** ì´í•´í•˜ê³ , ì™œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì¸ì§€ ì‚´í´ë´…ë‹ˆë‹¤.
2. Hugging Face `datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ **ì‹¤ì œ MMLU ë°ì´í„°ë¥¼ ë¡œë“œ**í•©ë‹ˆë‹¤.
3. SOLAR-mini APIë¥¼ ì´ìš©í•´ì„œ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆë„ë¡ **Baseline í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„**í•©ë‹ˆë‹¤.
4. ëª¨ë¸ì˜ ì¶œë ¥ ê²°ê³¼ì—ì„œ **ì •ë‹µì„ ì¶”ì¶œí•˜ê³  ì±„ì **í•˜ëŠ” í‰ê°€ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
5. ì´ë¥¼ í†µí•´ Baseline ì •í™•ë„(Accuracy)ë¥¼ ê³„ì‚°í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

---

## ì™œ Baselineì´ ì¤‘ìš”í•œê°€?

í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ë‚˜ ê¸°ë²• ê°œì„ ì„ í•˜ê¸° ì „ì— ë°˜ë“œì‹œ í•„ìš”í•œ ê²ƒì´ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ â€œì•„ë¬´ê²ƒë„ ì•ˆ í–ˆì„ ë•Œì˜ ê¸°ì¤€ ì„±ëŠ¥(Baseline)â€ì…ë‹ˆë‹¤.

---

## ë¯¸ì…˜ì„ ë§ˆì¹˜ê³  ë‚˜ë©´

ì´ ë¯¸ì…˜ì„ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

- âœ”ï¸ MMLU ë°ì´í„° êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ë‹¤ë£° ìˆ˜ ìˆë‹¤.
- âœ”ï¸ API ê¸°ë°˜ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤.
- âœ”ï¸ í‰ê°€ ê´€ë ¨ Frameworkë¥¼ ìµí ìˆ˜ ìˆë‹¤.  
- âœ”ï¸ â€œí”„ë¡¬í”„íŠ¸ê°€ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤€ë‹¤â€ëŠ” ë§ì„ **ìˆ«ìë¡œ í™•ì¸**í•  ìˆ˜ ìˆë‹¤  


ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ MMLU ë°ì´í„°ë¥¼ ì‚´í´ë³´ë©° ë¯¸ì…˜ì„ ì‹œì‘í•´ë´…ì‹œë‹¤ ğŸš€


Refer: Hugging Face `cais/mmlu` Dataset Card / Upstage SOLAR Model Card  
- MMLU: https://huggingface.co/datasets/cais/mmlu  
- SOLAR-Mini: https://www.upstage.ai/blog/en/introducing-solar-mini-compact-yet-powerful


# MMLU ë°ì´í„°ì…‹ ê°œìš” ì„¤ëª…
## 1ï¸âƒ£ MMLUë€ ë¬´ì—‡ì¸ê°€?

MMLU (Massive Multitask Language Understanding)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ **ì–¼ë§ˆë‚˜ í­ë„“ì€ ì§€ì‹ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆëŠ”ì§€**ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ ëŒ€í‘œì ì¸ **ê°ê´€ì‹ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤.

MMLUëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤.

- ë‹¤ì–‘í•œ ë¶„ì•¼(ìˆ˜í•™, ê³¼í•™, ì—­ì‚¬, ë²•ë¥ , ì˜í•™ ë“±)ì˜ ë¬¸ì œ í¬í•¨
- ê° ë¬¸ì œëŠ” **ê°ê´€ì‹(ë³´í†µ 4ì§€ì„ ë‹¤)** í˜•íƒœ
- ë‹¨ìˆœ ì•”ê¸°ë¿ ì•„ë‹ˆë¼ **ì§€ì‹ ì´í•´ + ì¶”ë¡  ëŠ¥ë ¥**ì„ í•¨ê»˜ ìš”êµ¬

ì¦‰, MMLUëŠ”  
> â€œëª¨ë¸ì´ íŠ¹ì • í•œ ë¶„ì•¼ë§Œ ì˜í•˜ëŠ”ê°€?â€ê°€ ì•„ë‹ˆë¼  
> â€œì „ë°˜ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë˜‘ë˜‘í•œê°€?â€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
---

## 2ï¸âƒ£ ì™œ MMLUë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?

LLMì„ í‰ê°€í•  ë•Œ ê°€ì¥ ì–´ë ¤ìš´ ì ì€ â€œë¬´ì—‡ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜í•œë‹¤ê³  ë§í•  ê²ƒì¸ê°€?â€ì…ë‹ˆë‹¤.

MMLUê°€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

- âœ”ï¸ ì—¬ëŸ¬ ë¶„ì•¼ë¥¼ ì•„ìš°ë¥´ëŠ” **ì¢…í•©ì ì¸ í‰ê°€**
- âœ”ï¸ ì •ë‹µì´ ëª…í™•í•œ ê°ê´€ì‹ ë¬¸ì œ â†’ **ì •ëŸ‰ì  ë¹„êµ ê°€ëŠ¥**
- âœ”ï¸ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ë™ì¼í•œ ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ ê°€ëŠ¥
- âœ”ï¸ ì‹¤ì œ ì—°êµ¬ì™€ ì‹¤ë¬´ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í‘œì¤€ ë²¤ì¹˜ë§ˆí¬

ê·¸ë˜ì„œ MMLUëŠ”:
- ë…¼ë¬¸
- Open LLM Leaderboard
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸

ë“±ì—ì„œ **ê¸°ë³¸ í‰ê°€ ì§€í‘œ**ë¡œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.

## MMLUì— ëŒ€í•œ ì „ì²˜ë¦¬ (EDA) ì§„í–‰

### MMLU ë°ì´í„° ë¡œë“œ

### (Todo1) MMLUì˜ ë¶„ì•¼(Subject) êµ¬ì„±

MMLUëŠ” ë‹¨ì¼ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ê°€ ì•„ë‹ˆë¼, **ë‹¤ì–‘í•œ í•™ë¬¸Â·ì§€ì‹ ì˜ì—­ì— ê±¸ì¹œ ë¬¸ì œë“¤**ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ëŒ€ëµì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì•¼ë“¤ì´ í¬í•¨ë©ë‹ˆë‹¤.

- ğŸ“ ìˆ˜í•™ / ë…¼ë¦¬  
  - abstract_algebra, linear_algebra, probability ë“±
- ğŸ§ª ê³¼í•™  
  - physics, chemistry, biology
- ğŸ§  ì˜í•™ / ìƒëª…ê³¼í•™  
  - clinical_knowledge, medical_genetics
- âš–ï¸ ë²•í•™ / ìœ¤ë¦¬  
  - professional_law, moral_scenarios
- ğŸ’» ì»´í“¨í„° ê³¼í•™  
  - computer_security, machine_learning
- ğŸŒ ì¸ë¬¸ / ì‚¬íšŒ  
  - world_history, philosophy, sociology

ì´ì²˜ëŸ¼ MMLUëŠ” **LLMì˜ ì „ë°˜ì ì¸ ì§€ì‹ í­ê³¼ ì¶”ë¡  ëŠ¥ë ¥**ì„ í‰ê°€í•˜ëŠ” ë° ì´ˆì ì´ ë§ì¶°ì§„ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.


from datasets import get_dataset_config_names

# MMLUì— í¬í•¨ëœ ëª¨ë“  subject ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
subjects = get_dataset_config_names("cais/mmlu")

print(f"ì´ subject ê°œìˆ˜: {len(subjects)}\n")
print("Subject ëª©ë¡:") # ì—¬ëŸ¬ subjectë¡œ ë°”ê¿”ê°€ë©´ì„œ ì‹¤í—˜ í‰ê°€í•´ë³´ê¸°
print(subjects)

# TODO 1: ìœ„ Subject ëª©ë¡ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©í•  subject í•˜ë‚˜ë¥¼ ì§€ì •í•˜ì‹œì˜¤
# íŒíŠ¸: MMLUì˜ subject ì´ë¦„ì€ ëª¨ë‘ ì†Œë¬¸ìì´ë©°, ê³µë°± ëŒ€ì‹  '_'ë¥¼ ì‚¬ìš©í•œë‹¤
# ì˜ˆì‹œ: "philosophy", "abstract_algebra", "anatomy" ...
SUBJECT = "astronomy"

from datasets import load_dataset

# ì˜ˆì‹œ: í•˜ë‚˜ì˜ subjectë§Œ ì‚¬ìš©
dataset = load_dataset("cais/mmlu", SUBJECT)


# ê° splitì˜ ë°ì´í„° ê°œìˆ˜ í™•ì¸
for split in dataset:
    print(f"{split}: {len(dataset[split])}")


### MMLU ìƒ˜í”Œì˜ ì£¼ìš” í•„ë“œ

í•˜ë‚˜ì˜ MMLU ìƒ˜í”Œì€ ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- **question**: ë¬¸ì œ ë³¸ë¬¸
- **choices**: ì„ íƒì§€ ëª©ë¡ (ë³´í†µ 4ê°œ)
- **answer**: ì •ë‹µ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)

### (Todo2, Todo3) êµ¬ì¡° ì‚´í´ë³´ê¸°

# í•˜ë‚˜ì˜ ìƒ˜í”Œ ì¶œë ¥
sample = dataset["test"][100]
sample


# ì„ íƒì§€ ê°œìˆ˜ ë¶„í¬ í™•ì¸

# TODO 2: test splitì— í¬í•¨ëœ ê° sampleì— ëŒ€í•´ ì„ íƒì§€ ê°œìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤
# íŒíŠ¸: for-loop ë˜ëŠ” list comprehensionì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤
# choice_lengths = 0
# for choice in (dataset["test"]):
#     choice_lengths += (len(choice["choices"]))
# choice_lengths

choice_lengths = [] # 0ì´ ì•„ë‹ˆë¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘
for choice in dataset["test"]:
    choice_lengths.append(len(choice["choices"])) # ë”í•˜ëŠ” ëŒ€ì‹  ì¶”ê°€(append)

# testì— ëŒ€í•´ì„œ íŠ¹ì • ì„ íƒì§€ë¡œ ì •ë‹µì´ ì¹˜ìš°ì³ ìˆì§€ ì•Šì€ì§€ íŒë‹¨
# ì¹˜ìš°ì³ì ¸ ìˆìœ¼ë©´ ì˜¬ë°”ë¥´ê²Œ í‰ê°€í•˜ê¸° ì–´ë ¤ì›€

from collections import Counter

"""
TODO 3: Counterë¥¼ ì‚¬ìš©í•´ ì •ë‹µ(ì„ íƒì§€) ë¶„í¬ë¥¼ í™•ì¸í•˜ì‹œì˜¤.

- dataset["test"]ì˜ ê° sampleì€ ë”•ì…”ë„ˆë¦¬ì´ë©°, "answer" í‚¤ì— ì •ë‹µì´ ë“¤ì–´ìˆë‹¤.
- MMLUì˜ "answer"ëŠ” ë³´í†µ 0ë¶€í„° ì‹œì‘í•˜ëŠ” index(0=A, 1=B, 2=C, 3=D)ì´ë‹¤.
- ë¨¼ì € ëª¨ë“  sampleì—ì„œ answerë§Œ ëª¨ì•„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“  ë’¤, Counterë¡œ ë¹ˆë„ìˆ˜ë¥¼ ì„¸ë©´ ëœë‹¤.
"""

# TODO 3-1: test splitì—ì„œ ê° sampleì˜ ì •ë‹µ indexë¥¼ ëª¨ì•„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“œì‹œì˜¤
# íŒíŠ¸: list comprehension ì‚¬ìš© (sample["answer"])
answers = []
for sample in dataset["test"]:
    answers.append(sample["answer"])

# TODO 3-2: Counterë¡œ ì •ë‹µ ë¶„í¬ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤
answer_dist = Counter(answers)

answer_dist



ì¦‰, ì •ë‹µì€ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼ `choices` ë¦¬ìŠ¤íŠ¸ì˜ **ì¸ë±ìŠ¤ ë²ˆí˜¸**ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ‘‰ í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ì´ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ **A/B/C/D í˜•íƒœë¡œ ë³€í™˜**í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.


# sampleì´ ë“¤ì–´ì™”ì„ ë•Œ ê¸°ë³¸ì ì¸ promptë¡œ ë§Œë“¤ê¸° ìœ„í•œ í•¨ìˆ˜ (basic formatting)

def format_mmlu_prompt(sample):
    question = sample["question"]
    choices = sample["choices"]

    prompt = question + "\n\n"
    for i, choice in enumerate(choices):
        prompt += f"{chr(ord('A') + i)}. {choice}\n"
    prompt += "\nAnswer:"

    return prompt

print(format_mmlu_prompt(dataset["test"][0]))


### EDAë¥¼ í†µí•´ í™•ì¸í•œ í‰ê°€ì— í•„ìš”í•œ ìš”ì†Œ

MMLU í‰ê°€ë¥¼ ìœ„í•´ ë‹¤ìŒ ìš”ì†Œë“¤ì´ í•„ìš”í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

1. ë¬¸ì œ ë³¸ë¬¸ (`question`)
2. ì„ íƒì§€ ëª©ë¡ (`choices`)
3. ì •ë‹µ ì¸ë±ìŠ¤ (`answer`)
4. ì •ë‹µì„ ë¬¸ì(A/B/C/D)ë¡œ ë³€í™˜í•˜ëŠ” ë¡œì§
5. ëª¨ë¸ ì…ë ¥ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

ì´ì œ ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
- ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³ 
- ì¶œë ¥ì„ ë°›ì•„
- ì •ë‹µì„ ì¶”ì¶œí•˜ê³ 
- ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ëŠ”  
**Baseline í‰ê°€ íŒŒì´í”„ë¼ì¸**ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


# (Use own key) Solar ëª¨ë¸ ì†Œê°œ

## Solar ëª¨ë¸ ì†Œê°œ (API ê¸°ë°˜ ì‚¬ìš©)

ì´ë²ˆ Daily Missionì—ì„œëŠ” **Upstageì˜ Solar ëª¨ë¸ì„ API ë°©ì‹ìœ¼ë¡œë§Œ ì‚¬ìš©**í•©ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì„ Hugging Faceì—ì„œ ì§ì ‘ ë¡œë“œí•˜ê±°ë‚˜ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì§€ ì•Šê³ , **API Keyë¥¼ í†µí•´ ì›ê²©ìœ¼ë¡œ í˜¸ì¶œ**í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.

---

### Solar ëª¨ë¸ì´ë€?

**Solar**ëŠ” Upstageì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ë¡œ, ë‹¤ì–‘í•œ ì–¸ì–´ ì´í•´ ë° ì¶”ë¡  ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.

íŠ¹íˆ Solar ëª¨ë¸ì€:
- ì§ˆë¬¸ì— ëŒ€í•´ ë¹„êµì  **ëª…í™•í•˜ê³  ì¼ê´€ëœ í˜•ì‹ì˜ ì‘ë‹µ**ì„ ìƒì„±í•˜ë©°
- ì‹¤ì œ ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ **API í˜•íƒœë¡œ ì œê³µ**ë©ë‹ˆë‹¤.

import os
os.environ["UPSTAGE_API_KEY"] = "up_w8c0bYvkD7x9OUmUjJrzPlRv8GlLV"

import time
from openai import OpenAI

client = OpenAI(
    api_key=os.environ["UPSTAGE_API_KEY"],
    base_url="https://api.upstage.ai/v1"
)


def call_model_api(prompt, model="solar-mini-250422"):
    """
    API Keyë¥¼ ì‚¬ìš©í•´ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ëª¨ë¸ ì‘ë‹µì„ ë°˜í™˜
    """
    start_time = time.time()

    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "user",
                "content": prompt
            }
        ],
        stream=False,
        temperature=0.0,
        max_tokens=256 # prompt ì„¤ê³„ì— ë”°ë¼ max token ìˆ˜ë¥¼ ì¤„ì—¬ë„ ë¨
    )

    elapsed_time = time.time() - start_time

    output_text = response.choices[0].message.content

    return output_text, elapsed_time


# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
prompt = "What is the capital of í•œêµ­? Answer with a single word to í•œêµ­ì–´."

# API í˜¸ì¶œ
output_text, elapsed_time = call_model_api(prompt)

print("=== API Raw Output ===")
print(output_text)

# Promptë€?

## (Todo4) Baseline Prompt ì„¤ê³„

# sampleì´ ë“¤ì–´ì™”ì„ ë•Œ ê¸°ë³¸ì ì¸ promptë¡œ ë§Œë“¤ê¸° ìœ„í•œ í•¨ìˆ˜ (basic formatting)

def format_mmlu_prompt_basic(sample):
    question = sample["question"]
    choices = sample["choices"]

    prompt = question + "\n\n"
    for i, choice in enumerate(choices):
        prompt += f"{chr(ord('A') + i)}. {choice}\n"

    return prompt

print(format_mmlu_prompt_basic(dataset["test"][0]))


# êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ ì‘ì„±

def build_instruction():
    """
    TODO 4:
    ì´ í•¨ìˆ˜ëŠ” LLMì—ê²Œ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í’€ê³ , ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë‹µì„ ì¶œë ¥í•´ì•¼ í•˜ëŠ”ì§€
    ëª…í™•í•˜ê²Œ ì§€ì‹œí•˜ëŠ” instruction ë¬¸ìì—´ì„ ìƒì„±í•œë‹¤.

    ì¤‘ìš”:
    - ì´í›„ ë‹¨ê³„ì—ì„œ ëª¨ë¸ ì¶œë ¥ì—ì„œ ì •ë‹µì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•œë‹¤.
    - ë”°ë¼ì„œ ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ "ì¼ê´€ë˜ê³  ë‹¨ìˆœ"í•´ì•¼ í•œë‹¤.
    """

    return (
        # TODO 4-1: ê°ê´€ì‹ ë¬¸ì œì„ì„ ëª…ì‹œí•˜ì‹œì˜¤
        "ê°ê´€ì‹ ë¬¸ì œ.\n"

        # TODO 4-2: ì„ íƒì§€ëŠ” A, B, C, D ì¤‘ í•˜ë‚˜ì„ì„ ëª…í™•íˆ í•˜ì‹œì˜¤
        "ì„ íƒì§€ëŠ” A,B,C,D ë„¤ê°€ì§€ì´ê³  ë„· ì¤‘ ë°˜ë“œì‹œ í•˜ë‚˜ë¥¼ ê³ ë¥´ì‹œì˜¤\n"

        # TODO 4-3: ì¶œë ¥ í˜•ì‹ì— ëŒ€í•œ ì œì•½ì„ ì¶”ê°€í•˜ì‹œì˜¤

        "ì¼ê´€ë˜ê³  ë‹¨ìˆœí•˜ê²Œ ì¶œë ¥\n"
    )


# systemì— ëŒ€í•œ roleì„ ê¸°ì¬í•´ì„œ í˜ë¥´ì†Œë‚˜ ë¶€ì—¬

def build_persona():
    return (
        # TODO 4-4: ëª¨ë¸ì„ ì „ë¬¸ê°€ë¡œ ì„¤ì •í•˜ëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì‹œì˜¤
        # íŒíŠ¸: expert, knowledge, academic domains ì™€ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤
        "ë‹¹ì‹ ì€ ì²œë¬¸í•™ë°•ì‚¬ì•„ì 10ë…„ì°¨ ì‹¤ë¬´ì „ë¬¸ê°€.\n\n"
    )

# chain of thoughtì„ ìœ„í•œ instruction ì‘ì„±

def build_cot_instruction():
  """
  TODO:
  ì´ í•¨ìˆ˜ëŠ” ëª¨ë¸ì´ ë°”ë¡œ ë‹µì„ ë‚´ê¸° ì „ì— 'ë‹¨ê³„ì ìœ¼ë¡œ ì‚¬ê³ 'í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ë¬¸ì¥ì„ ë§Œë“ ë‹¤.

  - CoT ìœ ë„ëŠ” ì–´ë ¤ìš´ ë¬¸ì œì—ì„œ ì •ë‹µë¥ ì„ ì˜¬ë¦¬ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.
  - ë‹¨, ìµœì¢… ì¶œë ¥ì€ í‰ê°€ë¥¼ ìœ„í•´ 'ì •í•´ì§„ í˜•ì‹'ì´ì–´ì•¼ í•œë‹¤ëŠ” ì ì— ì£¼ì˜í•˜ì.
  """

  return (
      # TODO 4-5: ë‹¨ê³„ì  ì¶”ë¡ ì„ ìœ ë„í•˜ëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì‹œì˜¤
      "ë¬¸ì œë¥¼ ë³´ê³  ë‹¨ê³„ì ìœ¼ë¡œ ë‹µì„ ì°¾ì•„ê°€ ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ì‹œì˜¤. ëª¨ë“  ì¶”ë¡ ì´ ëë‚˜ë©´, ë°˜ë“œì‹œ ë§ˆì§€ë§‰ ì¤„ì— ì •ë‹µ ì•ŒíŒŒë²³ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\n"
  )

# ì˜ˆì‹œë¡œ ì‚¬ìš©í•  ë°ì´í„°

dataset["dev"][1]

idx = dataset["dev"][0]["answer"]
letter = chr(ord('A') + idx)

# ì˜ˆì‹œ ì„¤ì •

def build_icl_examples():
    return (
        "Example:\n"
        f"Question: {dataset["dev"][0]["question"]}\n"
        f"A. {dataset["dev"][0]["choices"][0]}\n"
        f"B. {dataset["dev"][0]["choices"][1]}\n"
        f"C. {dataset["dev"][0]["choices"][2]}\n"
        f"D. {dataset["dev"][0]["choices"][3]}\n"
        f"Answer: {letter}\n\n"
    )

def format_mmlu_prompt_custom(
    sample,
    use_instruction=False,
    use_persona=False,
    use_icl=False,
    use_cot=False
):
    prompt = ""

    if use_persona:
        prompt += build_persona()

    if use_icl:
        prompt += build_icl_examples()

    if use_cot:
        prompt += build_cot_instruction()

    if use_instruction:
      prompt += build_instruction()

    # ë¬¸ì œ ë³¸ë¬¸
    prompt += sample["question"] + "\n\n"
    for i, choice in enumerate(sample["choices"]):
        prompt += f"{chr(ord('A') + i)}. {choice}\n"

    prompt += "\nAnswer:"

    return prompt


sample = dataset["test"][0]

print("=== Baseline ===")
print(format_mmlu_prompt_basic(sample))



print("\n=== All Techniques ===")
print(format_mmlu_prompt_custom(sample, use_instruction=True, use_persona=True, use_icl=True, use_cot=True))

# ëª¨ë¸ í‰ê°€ ì§„í–‰

## ëª¨ë¸ì„ ì–´ë–»ê²Œ í‰ê°€í•  ìˆ˜ ìˆì„ê¹Œ?

ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ”:
- MMLU ë°ì´í„° êµ¬ì¡°ë¥¼ ì‚´í´ë³´ê³ 
- ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ë°©ë²•ì„ ìµíˆê³ 
- í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

ì´ì œ ë‚¨ì€ ì§ˆë¬¸ì€ í•˜ë‚˜ì…ë‹ˆë‹¤.

> **â€œì´ ëª¨ë¸ì´ ì˜í•˜ê³  ìˆëŠ”ì§€, ì–´ë–»ê²Œ íŒë‹¨í•  ìˆ˜ ìˆì„ê¹Œ?â€**

---
### 1ï¸âƒ£ LLM í‰ê°€ëŠ” ì™œ ì–´ë ¤ìš´ê°€?

ì¼ë°˜ì ì¸ í”„ë¡œê·¸ë¨ê³¼ ë‹¬ë¦¬, LLMì˜ ì¶œë ¥ì€ í•­ìƒ ë™ì¼í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

- ê°™ì€ ì§ˆë¬¸ì—ë„ í‘œí˜„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê³ 
- ì •ë‹µì„ ì•Œê³  ìˆì–´ë„ ì¥í™©í•œ ì„¤ëª…ì„ í•  ìˆ˜ ìˆìœ¼ë©°
- ë•Œë¡œëŠ” ì• ë§¤í•œ ë‹µì„ ë‚´ë†“ê¸°ë„ í•©ë‹ˆë‹¤.

ê·¸ë˜ì„œ LLM í‰ê°€ëŠ” **â€œì¶œë ¥ì„ ì‚¬ëŒì´ ì½ê³  íŒë‹¨â€í•˜ëŠ” ë°©ì‹ë§Œìœ¼ë¡œëŠ” í•œê³„**ê°€ ìˆìŠµë‹ˆë‹¤.
---
### 2ï¸âƒ£ MMLUì—ì„œì˜ í‰ê°€ ê¸°ì¤€

MMLUëŠ” ì´ ë¬¸ì œë¥¼ **ê°ê´€ì‹ ë¬¸ì œ**ë¡œ í•´ê²°í•©ë‹ˆë‹¤.

- ê° ë¬¸ì œì—ëŠ” ëª…í™•í•œ ì •ë‹µì´ ìˆê³ 
- ëª¨ë¸ì€ ì„ íƒì§€(A, B, C, D) ì¤‘ í•˜ë‚˜ë¥¼ ê³ ë¥´ë©´ ë©ë‹ˆë‹¤.
- í‰ê°€ ì§€í‘œëŠ” ë§¤ìš° ë‹¨ìˆœí•©ë‹ˆë‹¤.

> **ì •í™•ë„(Accuracy) = ë§íŒ ë¬¸ì œ ìˆ˜ / ì „ì²´ ë¬¸ì œ ìˆ˜**

ì¦‰, í‰ê°€ì˜ í•µì‹¬ì€:
> **â€œëª¨ë¸ì´ ì„ íƒí•œ ë‹µê³¼ ì •ë‹µì´ ê°™ì€ê°€?â€**
---
### 3ï¸âƒ£ í‰ê°€ íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ ë‹¨ê³„

MMLU ê¸°ë°˜ í‰ê°€ íŒŒì´í”„ë¼ì¸ì€ ë³´í†µ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤.

1. ë¬¸ì œ + ì„ íƒì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì„±
2. ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ â†’ ì¶œë ¥ ìƒì„±
3. ì¶œë ¥ì—ì„œ **ì •ë‹µ(A/B/C/D) ì¶”ì¶œ**
4. ì •ë‹µê³¼ ë¹„êµ
5. ì •í™•ë„ ê³„ì‚°

ì´ ì¤‘ ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ëŠ” ì •ë‹µ ì¶”ì¶œ(Answer Extraction)ì…ë‹ˆë‹¤.

---
### 4ï¸âƒ£ ì™œ ì •ë‹µ ì¶”ì¶œì´ ì¤‘ìš”í•œê°€?

ëª¨ë¸ì€ í•­ìƒ ê¹”ë”í•˜ê²Œ `A`ë§Œ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
- `The correct answer is B.`
- `I think the answer is (C).`
- `After reasoning, the answer is D.`

ë”°ë¼ì„œ í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ëª¨ë¸ì˜ ìì—°ì–´ ì¶œë ¥ì„ ê¸°ê³„ì ìœ¼ë¡œ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœ(A/B/C/D)ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.


## ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ MMLUì— ëŒ€í•œ í‰ê°€ë¥¼ ì§„í–‰í•˜ëŠ”ì§€

### (Todo5) extract í•¨ìˆ˜ ì‘ì„±í•˜ê¸°


import re

def extract_answer_from_output(output_text, choices=("A", "B", "C", "D")):
    if output_text is None:
        return None

    # ì†Œë¬¸ìë¡œ ì˜¬ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ëŒ€ë¬¸ìë¡œ í†µì¼í•˜ê³  ì–‘ë ê³µë°± ì œê±°
    output_text = output_text.strip().upper()

    # TODO 5-1: ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ A/B/C/D ë‹¨ë… ë¬¸ì ì°¾ê¸°
    # íŒ¨í„´ ì„¤ëª…: \bëŠ” ë‹¨ì–´ì˜ ê²½ê³„ì…ë‹ˆë‹¤. ì¦‰, "APPLE"ì˜ Aê°€ ì•„ë‹ˆë¼ "A"ë§Œ ë”°ë¡œ ìˆì„ ë•Œ ì°¾ìŠµë‹ˆë‹¤.
    # [A-D]ëŠ” A, B, C, D ì¤‘ í•˜ë‚˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    pattern = r"\b([A-D])\b"
    matches = re.findall(pattern, output_text)

    if matches:
        # ê°€ì¥ ë¨¼ì € ë°œê²¬ëœ ì„ íƒì§€ë¥¼ ë°˜í™˜ (ë˜ëŠ” ë§ˆì§€ë§‰ ê²ƒì„ ë°˜í™˜í•˜ë„ë¡ matches[-1] ì‚¬ìš© ê°€ëŠ¥)
        return matches[0]

    # TODO 5-2: ì¶”ê°€ì ì¸ ê·œì¹™ (Answer: C ê°™ì€ êµ¬ì²´ì  íŒ¨í„´ ì²˜ë¦¬)
    # ëª¨ë¸ì´ "The answer is B"ë¼ê³  í•  ë•Œ 'answer'ë¼ëŠ” ë‹¨ì–´ ë°”ë¡œ ë’¤ì˜ ê¸€ìë¥¼ ì°¾ëŠ” ê·œì¹™
    match = re.search(r"ANSWER\s*:\s*([A-D])", output_text)
    if match:
        return match.group(1)

    # ëª¨ë“  ê·œì¹™ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    return None

test_outputs = [
    "A",
    "The correct answer is B.",
    "After reasoning, the answer is C.",
    "I think it is D",
    "I'm not sure.",
]

for text in test_outputs:
    print(f"Output: {text}")
    print("Extracted:", extract_answer_from_output(text))
    print("-" * 30)


### ì±„ì  í•¨ìˆ˜ êµ¬í˜„

def index_to_answer_letter(index):
    """
    MMLU ì •ë‹µ ì¸ë±ìŠ¤(0,1,2,3)ë¥¼ ë¬¸ì(A,B,C,D)ë¡œ ë³€í™˜
    """
    return chr(ord("A") + index)

def evaluate_predictions(pred_outputs, gold_answers, verbose=True):
    """
    ëª¨ë¸ ì¶œë ¥ê³¼ ì •ë‹µì„ ë¹„êµí•´ ì •í™•ë„(Accuracy)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜

    Parameters
    ----------
    pred_outputs : list[str]
        ëª¨ë¸ì´ ìƒì„±í•œ ì›ë³¸ ì¶œë ¥ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
    gold_answers : list[int]
        ì •ë‹µ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (0,1,2,3)
    verbose : bool
        Trueì¼ ê²½ìš° ê° ìƒ˜í”Œì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì¶œë ¥

    Returns
    -------
    dict
        {
            "accuracy": float,
            "total": int,
            "correct": int,
            "details": list[dict]
        }
    """

    total = len(pred_outputs)
    correct = 0
    details = []

    for output_text, gold_idx in zip(pred_outputs, gold_answers):
        extracted = extract_answer_from_output(output_text)
        gold_letter = index_to_answer_letter(gold_idx)

        is_correct = (extracted == gold_letter)
        if is_correct:
            correct += 1

        details.append({
            "model_output": output_text,
            "extracted_answer": extracted,
            "gold_answer": gold_letter,
            "is_correct": is_correct
        })

        if verbose:
            print("Model output:", output_text)
            print("Extracted answer:", extracted)
            print("Gold answer:", gold_letter)
            print("Correct:", is_correct)
            print("-" * 50)

    accuracy = correct / total if total > 0 else 0.0

    return {
        "accuracy": accuracy,
        "total": total,
        "correct": correct,
        "details": details
    }

# ì˜ˆì‹œ í…ŒìŠ¤íŠ¸
pred_outputs = [
    "The correct answer is B.",
    "A",
    "I think it is C.",
    "Not sure."
]

gold_answers = [1, 0, 2, 3]  # B, A, C, D

result = evaluate_predictions(pred_outputs, gold_answers, verbose=True)

print("Final Accuracy:", result["accuracy"]* 100)


# ì±„ì  ì§„í–‰ ë° ê²°ê³¼ í™•ì¸
- ëª¨ë¸ì˜ ì‹¤ì œ response í™•ì¸
- ì¶”ì¶œëœ ì •ë‹µì´ ë¬´ì—‡ì¸ì§€
- ì •ë‹µë¥  í™•ì¸

# í‰ê°€í•  ìƒ˜í”Œ ìˆ˜
NUM_SAMPLES = 20

# MMLU test ë°ì´í„° ì„ íƒ
test_samples = dataset["test"].select(range(NUM_SAMPLES))

## (1) Basic Prompt

from tqdm import tqdm

# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
model_outputs = []
extracted_preds = []
gold_answers = []
api_times = []

# í‰ê°€ ë£¨í”„ (API ì‚¬ìš©)
for sample in tqdm(test_samples):
    # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = format_mmlu_prompt_basic(sample) # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©

    # 2. API í˜¸ì¶œ (ì¶”ë¡ )
    output_text, elapsed_time = call_model_api(prompt)
    api_times.append(elapsed_time)

    model_outputs.append(output_text)

    # 3. ì •ë‹µ ì¶”ì¶œ
    pred = extract_answer_from_output(output_text)
    extracted_preds.append(pred)

    # 4. golden answer ì €ì¥
    gold_answers.append(sample["answer"])

# ============================================
# ê²°ê³¼ í‰ê°€
# ============================================

result = evaluate_predictions(
    pred_outputs=model_outputs,
    gold_answers=gold_answers,
    verbose=True
)

print("\n================ Evaluation Result (API) ================")
print(f"Total samples: {result['total']}")
print(f"Correct: {result['correct']}")
print(f"Accuracy: {result['accuracy'] * 100:.1f}")


## (2) Custom Prompt

from tqdm import tqdm

# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
model_outputs = []
extracted_preds = []
gold_answers = []
api_times = []

# í‰ê°€ ë£¨í”„ (API ì‚¬ìš©)
for sample in tqdm(test_samples):
    # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = format_mmlu_prompt_custom(sample, use_instruction=True, use_persona=True, use_icl=True)
    # 2. API í˜¸ì¶œ (ì¶”ë¡ )
    output_text, elapsed_time = call_model_api(prompt)
    api_times.append(elapsed_time)

    model_outputs.append(output_text)

    # 3. ì •ë‹µ ì¶”ì¶œ
    pred = extract_answer_from_output(output_text)
    extracted_preds.append(pred)

    # 4. golden answer ì €ì¥
    gold_answers.append(sample["answer"])

# ============================================
# ê²°ê³¼ í‰ê°€
# ============================================

result = evaluate_predictions(
    pred_outputs=model_outputs,
    gold_answers=gold_answers,
    verbose=True
)

print("\n================ Evaluation Result (API) ================")
print(f"Total samples: {result['total']}")
print(f"Correct: {result['correct']}")
print(f"Accuracy: {result['accuracy'] * 100:.1f}")


# ğŸ”¥[Daily Mission] Day 1(ì‹¬í™”) â€” MMLUì— ê°€ì¥ ìµœì ì˜ Few-shot í”„ë¡¬í”„íŠ¸ ì°¾ê¸°


## ì´ë²ˆ ë¯¸ì…˜ì—ì„œëŠ” ë‹¤ìŒ ìš”ì†Œë“¤ì„ ë°”ê¿”ê°€ë©° ì‹¤í—˜í•©ë‹ˆë‹¤.

### 1. Shot ìˆ˜
- Zero-shot: ì˜ˆì‹œ ì—†ìŒ
- Few-shot: ì˜ˆì‹œ 2ê°œ ì´ìƒ

### 2. ì˜ˆì‹œ ì„ íƒ ë°©ì‹
- ë™ì¼í•œ subjectì˜ ë¬¸ì œ
- ëœë¤ìœ¼ë¡œ ì„ íƒí•œ ë¬¸ì œ
- ìƒëŒ€ì ìœ¼ë¡œ ì‰¬ìš´ ë¬¸ì œ / ì–´ë ¤ìš´ ë¬¸ì œ ì¡°í•©


âš ï¸ ì£¼ì˜  
í•œ ë²ˆì— ëª¨ë“  ë³€ìˆ˜ë¥¼ ë°”ê¾¸ì§€ ë§ê³ , **í•œ ë²ˆì— í•˜ë‚˜ì˜ ë³€ìˆ˜ë§Œ ë³€ê²½í•˜ë©° ì‹¤í—˜**í•˜ì„¸ìš”.

subjectì— ë”°ë¼ ì˜ˆì‹œê°€ ì—†ëŠ” ê²ƒì´ ê°€ì¥ ë†’ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ subjectì— ëŒ€í•´ì„œ ì‹¤í—˜í•´ë³´ì„¸ìš”!




### Zero-shot Baseline í‰ê°€


from tqdm import tqdm

NUM_SAMPLES = 20
eval_samples = dataset["test"].select(range(NUM_SAMPLES))

zero_shot_outputs = []
zero_shot_golds = []

for sample in tqdm(eval_samples):
    prompt = format_mmlu_prompt_basic(sample)

    output_text, _ = call_model_api(prompt)
    zero_shot_outputs.append(output_text)
    zero_shot_golds.append(sample["answer"])

zero_shot_result = evaluate_predictions(
    pred_outputs=zero_shot_outputs,
    gold_answers=zero_shot_golds,
    verbose=True
)

print("\nZero-shot Accuracy:", zero_shot_result["accuracy"]*100)


### Few-shot í”„ë¡¬í”„íŠ¸ ì¼ë°˜í™” í•¨ìˆ˜

def format_mmlu_prompt_few_shot(sample, examples):
    """
    examples: MMLU sample(dict) ë¦¬ìŠ¤íŠ¸
    """
    prompt = ""

    for ex in examples:
        prompt += ex["question"] + "\n\n"
        for i, choice in enumerate(ex["choices"]):
            prompt += f"{chr(ord('A') + i)}. {choice}\n"
        prompt += f"\nAnswer: {chr(ord('A') + ex['answer'])}\n\n"

    # ì‹¤ì œ ë¬¸ì œ
    prompt += sample["question"] + "\n\n"
    for i, choice in enumerate(sample["choices"]):
        prompt += f"{chr(ord('A') + i)}. {choice}\n"
    prompt += "\nAnswer:"

    return prompt


# few-shot ì¡°í•©
few_shot_sets = {
    "random_2shot": [
        dataset["validation"][0],
        dataset["validation"][1]
    ],
    "random_3shot": [
        dataset["validation"][0],
        dataset["validation"][1],
        dataset["validation"][2]
    ]
}


sample = dataset["validation"][-1]
name, examples = list(few_shot_sets.items())[1] # random_3shotì˜ ì˜ˆì‹œ

few-shot-promptì— ëŒ€í•œ ì˜ˆì‹œ (ë³„ë‹¤ë¥¸ intructionì´ë‚˜ ê¸°ë²• ì—†ì´ shotë§Œ ì¶”ê°€)

few_shot_prompt = format_mmlu_prompt_few_shot(sample, examples)

print(few_shot_prompt)

### Few-shot ì˜ˆì‹œ ì¡°í•© ì‹¤í—˜

few_shot_sets = {
    "random_2shot": [
        dataset["validation"][0],
        dataset["validation"][1]
    ],
    "random_3shot": [
        dataset["validation"][0],
        dataset["validation"][1],
        dataset["validation"][2]
    ]
}

few_shot_results = {}

for name, examples in few_shot_sets.items():
    outputs = []
    golds = []

    for sample in tqdm(eval_samples):
        prompt = format_mmlu_prompt_few_shot(sample, examples)
        output_text, _ = call_model_api(prompt)
        outputs.append(output_text)
        golds.append(sample["answer"])

    result = evaluate_predictions(outputs, golds, verbose=False)
    few_shot_results[name] = result["accuracy"]
print()
for k, v in few_shot_results.items():
    print(f"{k}: {v*100}")


## (Todo) Best Few-shot ì¡°í•© ì„ íƒ

ì§€ê¸ˆê¹Œì§€ì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í•œ Few-shot ì˜ˆì‹œ ì¡°í•©ì„ ì„ íƒí•˜ì„¸ìš”.

### ì •ë¦¬ ì§ˆë¬¸
- ì–´ë–¤ ì¡°í•©ì´ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ëŠ”ê°€?
- Shot ìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ í•­ìƒ ì„±ëŠ¥ì´ ì¢‹ì•„ì¡ŒëŠ”ê°€?
- ì˜ˆì‹œì˜ â€œê°œìˆ˜â€ë³´ë‹¤ â€œì„ íƒ ë°©ì‹â€ì´ ë” ì¤‘ìš”í–ˆëŠ”ê°€?

ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ìƒê°í•˜ë©° ë‹¤ì–‘í•œ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•´ë´…ì‹œë‹¤.


###**ì½˜í…ì¸  ë¼ì´ì„ ìŠ¤**
<font color='red'><b>**(ì£¼)ì—…ìŠ¤í…Œì´ì§€ê°€ ì œê³µí•˜ëŠ” ëª¨ë“  êµìœ¡ ì½˜í…ì¸ ì˜ ì§€ì‹ì¬ì‚°ê¶Œì€
ìš´ì˜ ì£¼ì²´ì¸ (ì£¼)ì—…ìŠ¤í…Œì´ì§€ ë˜ëŠ” í•´ë‹¹ ì €ì‘ë¬¼ì˜ ì ë²•í•œ ê´€ë¦¬ìì—ê²Œ ê·€ì†ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**</b></font>

ì½˜í…ì¸  ì¼ë¶€ ë˜ëŠ” ì „ë¶€ë¥¼ **ë³µì‚¬, ë³µì œ, íŒë§¤, ì¬íŒë§¤ ê³µê°œ, ê³µìœ ** ë“±ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ ì¶œë  ê²½ìš° ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì— ëŒ€í•œ ì±…ì„ì„ ë¶€ë‹´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìœ ì¶œì— í•´ë‹¹í•˜ì—¬ ê¸ˆì§€ë˜ëŠ” í–‰ìœ„ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
* ì½˜í…ì¸ ë¥¼ ì¬ê°€ê³µí•˜ì—¬ ì˜¨/ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ê³µê°œí•˜ëŠ” í–‰ìœ„
* ì½˜í…ì¸ ì˜ ì¼ë¶€ ë˜ëŠ” ì „ë¶€ë¥¼ ì´ìš©í•˜ì—¬ ì¸ì‡„ë¬¼ì„ ë§Œë“œëŠ” í–‰ìœ„
* ì½˜í…ì¸ ì˜ ì „ë¶€ ë˜ëŠ” ì¼ë¶€ë¥¼ ë…¹ì·¨ ë˜ëŠ” ë…¹í™”í•˜ê±°ë‚˜ ë…¹ì·¨ë¡ì„ ì‘ì„±í•˜ëŠ” í–‰ìœ„
* ì½˜í…ì¸ ì˜ ì „ë¶€ ë˜ëŠ” ì¼ë¶€ë¥¼ ìŠ¤í¬ë¦° ìº¡ì³í•˜ê±°ë‚˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•˜ëŠ” í–‰ìœ„
* ì§€ì¸ì„ í¬í•¨í•œ ì œ3ìì—ê²Œ ì½˜í…ì¸ ì˜ ì¼ë¶€ ë˜ëŠ” ì „ë¶€ë¥¼ ê³µìœ í•˜ëŠ” í–‰ìœ„
* ë‹¤ë¥¸ ì •ë³´ì™€ ê²°í•©í•˜ì—¬ Upstage Educationì˜ ì½˜í…ì¸ ì„ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì €ì‘ë¬¼ì„ ì‘ì„±, ê³µê°œí•˜ëŠ” í–‰ìœ„
* ì œê³µëœ ë°ì´í„°ì˜ ì¼ë¶€ í˜¹ì€ ì „ë¶€ë¥¼ Upstage Education í”„ë¡œì íŠ¸/ì‹¤ìŠµ ìˆ˜í–‰ ì´ì™¸ì˜ ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” í–‰ìœ„