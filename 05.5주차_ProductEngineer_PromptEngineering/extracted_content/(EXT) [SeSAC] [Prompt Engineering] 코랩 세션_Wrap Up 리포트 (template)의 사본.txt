 
 
 
[Prompt
 
Engineering]
 
코랩세션
 
Wrap
 
Up
 
리포트
 
작성팀:
 
(이영기)
 
Wrap
 
Up
 
리포트
 
작성
 
내용
 
1)
 
논의
 
주제
 
a)
 
보라색으로
 
작성된
 
주제는
 
예시
 
주제로,
 
팀
 
내
 
논의하고
 
싶은
 
주제가
 
있다면
 
해당
 
주제로
 
논의해주세요!
 
2)
 
팀원별
 
핵심
 
아이디어
 
3)
 
논의
 
과정
 
4)
 
최종
 
논의
 
결과
 
및
 
회고
 
 
공통
 
예시
 
주제
 
(Day
 
01
 
-
 
Day
 
05)
 
 
 
Day
 
01
 
코랩
 
세션
 
 
논문
:
 
Language
 
Models
 
are
 
Unsupervised
 
Multitask
 
Learners
 
(GPT -2)
 
•
 
Unsupervised
 
Multitask
 
Learning
 
(
비지도
 
멀티태스크
 
학습
):
 
별도의
 
라벨링
 
된
 
데이터
(
지도
 
학습
)
 
없이
,
 
방대한
 
텍스트
 
학습만으로
 
번역
,
 
요약
 
등
 
다양한
 
태스크
 
수행
 
가능
.
 
•
 
WebText
 
(
데이터셋
):
 
Reddit
에서
 
3
개
 
이상의
 
추천
(
Karma)
을
 
받은
 
링크만
 
선별하여
 
구축한
 
고품질
 
데이터셋
 
(
약
 
40GB).
 
•
 
Zero-shot
 
Transfer
 
(
제로샷
 
전이
):
 
파라미터
 
수정
(
Fine-tuning)
 
없이
 
프롬프트
 
입력만으로
 
즉시
 
새로운
 
작업
 
수행
.
 
•
 
Capacity
 
(
용량의
 
중요성
):
 
모델
 
크기가
 
클수록
 
제로샷
 
성능이
 
로그
 
선형적으로
 
향상됨을
 
입증
.
 
•
 
성과
:
 
8
개
 
언어
 
모델링
 
벤치마크
 
중
 
7
개에서
 
최고
 
성능
(
SOTA)
 
달성
,
 
기계
 
독해
(
CoQA)
에서
 
훈련
 
없이
 
기존
 
시스템과
 
대등한
 
성능
 
기록
.
 
2.
 
논문
 
요약
 
및
 
핵심
 
아이디어
 
공유
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
이
 
논문은
 
거대
 
언어
 
모델이
 
별도의
 
라벨링
 
없이도
 
'
다음
 
단어
 
예측
'
이라는
 
단순한
 
학습을
 
통해
 
다양한
 
NLP
 
태스크를
 
수행할
 
수
 
있음을
 
증명했습니다
.
 
주요
 
핵심
 
아이디어는
 
다음과
 
같습니다
.
 
●
 
비지도
 
멀티태스킹
 
학습의
 
가능성
:
 
기존
 
모델은
 
특정
 
작업을
 
위해
 
$p(output|input)$
을
 
학습했지만
,
 
GPT-2
는
 
자연어
 
문맥
 
자체가
 
작업을
 
지시한다고
 
보고
 
p(output|input,
 
task)
를
 
학습합니다
 
.
 
즉
,
 
(translate
 
english
 
to
 
french,
 
text,
 
...)
와
 
같은
 
시퀀스를
 
학습하면
 
모델이
 
자연스럽게
 
번역
 
기능을
 
익히게
 
됩니다
.
 
 
●
 
고품질
 
데이터셋
 
'WebText'
의
 
중요성
:
 
무작위
 
웹
 
크롤링
 
데이터는
 
품질이
 
낮아
 
학습
 
효율이
 
떨어집니다
.
 
이를
 
극복하기
 
위해
 
Reddit
에서
 
3
점
 
이상의
 
추천
(
Karma)
을
 
받은
 
외부
 
링크만
 
선별하여
,
 
사람이
 
1
차적으로
 
검증한
 
고품질
 
텍스트
 
40GB
를
 
구축했습니다
.
 
 
●
 
유연한
 
입력
 
표현
 
(Byte-level
 
BPE):
 
단어
 
기반의
 
어휘
 
집합
 
제한을
 
없애기
 
위해
 
바이트
(
Byte)
 
수준의
 
BPE
를
 
도입했습니다
.
 
이를
 
통해
 
전처리
 
없이
 
이모지나
 
다국어를
 
포함한
 
어떤
 
유니코드
 
문자열도
 
처리할
 
수
 
있는
 
유연성을
 
확보했습니다
.
 
 
●
 
규모에
 
따른
 
성능
 
향상
:
 
모델
 
파라미터를
 
15
억
 
개
(1.5
B)
까지
 
늘렸을
 
때
 
성능이
 
로그
 
선형적으로
 
증가함을
 
확인했습니다
.
 
이는
 
모델의
 
용량
(
Capacity)
이
 
커질수록
 
다양한
 
태스크를
 
수행하는
 
능력이
 
향상됨을
 
의미합니다
.
  
 
●
 
주요
 
논의
 
과정
 
●
 
"
단순
 
암기인가
,
 
일반화인가
?"
 
○
 
모델이
 
방대한
 
텍스트를
 
단순히
 
외워서
 
답하는
 
것이
 
아닌가
 
하는
 
우려가
 
있었습니다
.
 
이에
 
대해
 
논문의
 
'
데이터
 
중복
 
분석
'
 
결과를
 
검토했습니다
.
 
○
 
WebText
 
학습
 
데이터와
 
평가
 
데이터
 
간의
 
8-gram
 
중복도는
 
약
 
3.2%
로
 
매우
 
낮았습니다
.
 
이는
 
다른
 
표준
 
데이터셋들의
 
자체
 
중복도
(5.9%)
보다도
 
낮은
 
수치입니다
.
 
따라서
 
모델의
 
높은
 
성능은
 
단순
 
암기가
 
아닌
 
데이터
 
패턴의
 
일반화
(
Generalization)
에
 
기인한
 
것으로
 
판단했습니다
.
 
 
○
 
 
●
 
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
●
 
"
데이터
 
품질이
 
모델
 
성능에
 
미치는
 
영향
"
 
○
 
단순히
 
데이터
 
양을
 
늘리는
 
것보다
 
'
질
 
좋은
 
데이터
'
를
 
선별하는
 
전략이
 
유효했음에
 
공감했습니다
.
 
특히
 
Reddit
의
 
추천
 
시스템을
 
품질
 
필터링의
 
도구로
 
활용한
 
점은
 
데이터
 
엔지니어링
 
관점에서
 
매우
 
창의적인
 
접근으로
 
평가되었습니다
 
○
 
또한
,
 
평가의
 
공정성을
 
위해
 
위키피디아
 
문서를
 
학습
 
데이터에서
 
전면
 
배제한
 
점도
 
인상
 
깊은
 
실험
 
설계였습니다
.
 
 
○
 
 
●
 
 
●
 
"
제로
 
샷
(
Zero-shot)
 
성능의
 
현실적
 
한계
"
 
○
 
언어
 
모델링이나
 
상식
 
추론
(
Winograd)
에서는
 
SOTA
를
 
달성했지만
 
,
 
요약이나
 
질의응답
(
QA)
 
같은
 
복잡한
 
생성
 
태스크에서는
 
아직
 
전용
 
지도
 
학습
 
모델에
 
비해
 
성능이
 
부족함을
 
확인했습니다
.
 
 
○
 
그럼에도
 
불구하고
,
 
15
억
 
파라미터
 
모델조차
 
데이터에
 
대해
 
과소적합
(
Underfitting)
 
상태라는
 
점은
,
 
향후
 
더
 
큰
 
모델과
 
데이터가
 
등장하면
 
성능이
 
비약적으로
 
상승할
 
잠재력이
 
있음을
 
시사했습니다
.
  
 
○
 
 
●
 
 
●
 
최종
 
논의
 
결과
 
및
 
회고
 
이번
 
논문
 
리뷰를
 
통해
 
도출된
 
결론과
 
회고는
 
다음과
 
같습니다
.
 
●
 
최종
 
결론
:
 
○
 
충분한
 
용량
(
Capacity)
을
 
가진
 
언어
 
모델에
 
고품질의
 
다양한
 
데이터를
 
학습시키면
,
 
명시적인
 
지도
 
학습
 
없이도
 
범용적인
 
작업
 
수행
 
능력을
 
갖춘
 
'
제너럴리스트
(
Generalist)'
 
모델을
 
만들
 
수
 
있습니다
.
 
○
 
특히
,
 
자연어
 
처리
 
연구의
 
패러다임이
 
'
특정
 
태스크
 
최적화
'
에서
 
'
대규모
 
비지도
 
사전
 
학습
(
Pre-training)'
으로
 
완전히
 
전환되고
 
있음을
 
확인했습니다
.
 
○
 
 
●
 
 
 
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
Day
 
02
 
코랩
 
세션
 
Day
 
02
 
코랩
 
세션
 
1)
 
논의
 
주제
 
●
 
미니
 
모델에서의
 
Plan-and-Solve
 
성능
 
저하
 
원인
 
분석
 
2)
 
팀원별
 
핵심
 
아이디어
 
●
 
미니
 
모델은
 
파라미터
 
수가
 
적어
 
처리할
 
수
 
있는
 
컨텍스트
 
밀도에
 
한계가
 
있다
.
 
프롬프트가
 
길어질수록
 
질문
 
자체에
 
집중하기보다
 
'
형식
(
Plan,
 
Solve,
 
특정
 
문자열
 
제한
)'
을
 
맞추는
 
데
 
연산
 
자원을
 
다
 
써버리는
 
것
 
같다
.
 
●
 
미니
 
모델은
 
답변의
 
앞부분에서
 
힘을
 
다
 
빼면
 
정작
 
정답을
 
내야
 
할
 
마지막
 
부분에서
 
어텐션
(
Attention)
이
 
흐트러진다
.
 
'Plan'
 
단계를
 
강제하는
 
것이
 
오히려
 
모델의
 
자연스러운
 
사고
 
흐름을
 
방해하는
 
'
가이드라인의
 
역설
'
이
 
발생한
 
것
 
같다
.
 
3)
 
논의
 
과정
 
●
 
현재
 
프롬프트는
 
1)
 
계획
 
수립
,
 
2)
 
단계별
 
해결
,
 
3)
 
정답
 
형식
 
지정
,
 
4)
 
정답
 
문자열
 
제한
 
등
 
4~5
개의
 
고난도
 
명령이
 
중첩되어
 
있음을
 
확인
 
●
 
동일
 
질문에
 
대해
 
단순한
 
프롬프트를
 
넣었을
 
때와
 
구체적인
 
프롬프트를
 
넣었을
 
때의
 
모델
 
출력값
 
비교
 
●
 
소형
 
모델에게는
 
'
복합
 
지시문
'
보다
 
'
직관적
 
트리거
'
가
 
더
 
효율적이다
"
라는
 
결론에
 
도달
 
4)
 
최종
 
논의
 
결과
 
및
 
회고
 
●
 
미니
 
모델용
 
프롬프트는
 
최소화
(
Minimalism)
가
 
원칙이다
.
 
●
 
Plan
과
 
Solve
를
 
엄격히
 
구분하기보다
,
 
모델이
 
스스로
 
사고를
 
전개할
 
수
 
있는
 
최소한의
 
공간만
 
제공하도록
 
프롬프트를
 
경량화하기로
 
결정
.
 
●
 
수정
 
방향
:
 
지시문을
 
3
줄
 
이내로
 
줄이고
,
 
모델이
 
가장
 
잘
 
이해하는
 
Step-by-step
 
구조로
 
단순화함
 
●
 
"
모델의
 
체급에
 
따라
 
'
좋은
 
프롬프트
'
의
 
정의가
 
달라진다는
 
점을
 
배웠습니다
.
 
고성능
 
모델에게는
 
'
정교한
 
설계도
'
가
 
도움이
 
되지만
,
 
미니
 
모델에게는
 
'
명확한
 
목적지
'
만
 
보여주는
 
것이
 
더
 
효과적이라는
 
것을
 
0.28
이라는
 
숫자를
 
통해
 
뼈저리게
 
느꼈습니다
.
 
이번
 
경험을
 
바탕으로
 
모델
 
사이즈별
 
프롬프트
 
전략을
 
이원화하여
 
접근할
 
예정입니다
."
 
 
 
Day
 
03
 
코랩
 
세션
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
 
1.
 
논의
 
주제
 
AI
 
모델
 
엔지니어링과
 
애플리케이션
(
백엔드
)
 
개발의
 
차이
,
 
그리고
 
개인
 
진로
 
선택에
 
대한
 
현실적
 
고민
 
●
 
모델
 
엔지니어링
 
vs
 
애플리케이션
 
개발의
 
업무
 
성격
 
차이
 
●
 
수학
·
이론
 
이해의
 
중요성과
 
진입
 
장벽
 
●
 
임베딩
,
 
코사인
 
유사도
,
 
청킹
/
토크나이징
 
등
 
수업
 
핵심
 
개념의
 
실제
 
의미
 
●
 
“
관심
”
과
 
“
현실적
 
선택
”
 
사이에서의
 
균형
 
---
 
2.
 
팀원별
 
핵심
 
아이디어
 
 
화자
 
1
 
●
 
모델
 
엔지니어링은
 
수학
(
미적분
,
 
선형대수
,
 
로그
 
등
)
 
이해
 
없이는
 
한계가
 
명확함
 
●
 
GPT·
임베딩
 
과제는
 
“
코드를
 
돌리는
 
것
”
보다
 
한
 
줄
 
한
 
줄의
 
의미를
 
이해하는
 
과정
이
 
중요
 
●
 
모델
 
엔지니어와
 
애플리케이션
 
개발자는
 
이분법이
 
아니라
 
겹치는
 
스펙트럼
 
●
 
엔지니어링에
 
대한
 
관심이
 
있다면
 
작은
 
과제라도
 
직접
 
해보며
 
적성
 
검증
이
 
필요
 
●
 
코사인
 
유사도는
 
벡터의
 
길이보다
 
방향
이
 
의미
 
있기
 
때문에
 
사용됨
 
 
화자
 
2
 
●
 
실제
 
현업
(
특히
 
CV,
 
YOLO
 
등
)
에서는
 
데이터
 
라벨링과
 
반복
 
작업
(
노가다
)
의
 
비중이
 
큼
 
●
 
자동화는
 
발전했지만
 
정확도
(70%
 
vs
 
85%)
 
차이
 
때문에
 
여전히
 
사람이
 
개입
 
●
 
모델
 
성능은
 
결국
 
정확도
 
싸움
,
 
작은
 
차이도
 
큰
 
의미를
 
가짐
 
 
화자
 
3
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
●
 
논문을
 
읽기
 
이전에
 
기초
 
수학부터
 
다시
 
해야
 
하는
 
현실
 
●
 
“
왜
 
그런
 
수식이
 
나오는지
”
 
이해하지
 
못하면
 
의미가
 
없음
 
●
 
청킹은
 
토큰화보다
 
덜
 
미세한
,
 
의미
 
단위
 
분할
로
 
이해
 
가능
 
 
화자
 
4
 
●
 
모델
 
엔지니어는
 
가설
 
설정
 
→
 
실험
 
→
 
실패
 
→
 
재설계
의
 
반복
 
●
 
하이퍼파라미터
 
하나가
 
다른
 
값에
 
연쇄적
 
영향을
 
미침
 
●
 
학습에는
 
시간
·
장비
 
비용
이
 
크기
 
때문에
 
가설을
 
날카롭게
 
세워야
 
함
 
●
 
백엔드
 
개발은
 
목표가
 
명확하지만
,
 
AI
 
모델링은
 
정답이
 
없는
 
상태에서
 
성능을
 
끌어올리는
 
작업
 
●
 
성향에
 
따라
 
모델링
 
업무는
 
큰
 
스트레스가
 
될
 
수
 
있음
 
---
 
3.
 
논의
 
과정
 
1.
 
모델
 
엔지니어링에
 
대한
 
관심
 
제기
 
●
 
석사
 
진학
,
 
모델링
 
경험
,
 
엔지니어링
 
적성에
 
대한
 
질문에서
 
시작
 
2.
 
현실적인
 
진입
 
장벽
 
논의
 
●
 
수학
 
이해의
 
필수성
 
○
 
논문
 
해석과
 
실제
 
구현
 
사이의
 
간극
 
●
 
 
3.
 
현업
 
사례
 
공유
 
●
 
YOLO
 
기반
 
CV
 
프로젝트
 
○
 
대규모
 
라벨링
,
 
반복적인
 
성능
 
개선
 
과정
 
●
 
 
4.
 
수업
 
개념
 
심화
 
토론
 
●
 
임베딩
 
차원은
 
고정이
 
아니라
 
하이퍼파라미터
 
○
 
고차원
 
공간에서
 
거리보다
 
방향이
 
중요한
 
이유
 
→
 
코사인
 
유사도
 
○
 
청킹
 
vs
 
토큰화
:
 
●
 
 
●
 
토큰
:
 
모델이
 
읽는
 
최소
 
단위
 
(
과금
·
제한
 
기준
)
 
○
 
청크
:
 
사람이
 
설계한
 
의미
 
단위
 
●
 
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
5.
 
진로에
 
대한
 
현실적
 
조언
 
●
 
“
무조건
 
모델
 
엔지니어
”
는
 
리스크
 
○
 
애플리케이션
 
개발을
 
하더라도
 
모델
 
이해는
 
강점이
 
됨
 
●
 
 
---
 
4.
 
최종
 
논의
 
결과
 
및
 
회고
 
 
최종
 
정리
 
●
 
모델
 
엔지니어링과
 
애플리케이션
 
개발은
 
완전히
 
다른
 
직무
 
●
 
요구
 
역량
,
 
스트레스
 
포인트
,
 
성취
 
방식이
 
다름
 
●
 
모델
 
엔지니어링은
:
 
●
 
수학
·
통계
 
기반
 
사고
 
○
 
정답
 
없는
 
문제를
 
다루는
 
인내심
 
○
 
긴
 
실험
 
주기를
 
감내할
 
수
 
있는
 
성향이
 
필요
 
●
 
 
●
 
애플리케이션
 
개발은
:
 
●
 
비교적
 
명확한
 
요구사항
 
○
 
구현
 
중심의
 
성취감
 
●
 
 
 
회고
 
●
 
“
멋있어
 
보여서
”
가
 
아니라
 
직접
 
해보고
 
판단해야
 
한다
 
●
 
작은
 
모델
 
튜닝
,
 
임베딩
 
과제라도
 
라인
 
단위
 
이해
가
 
중요
 
●
 
깊이를
 
선택하든
,
 
현실을
 
선택하든
 
모델
 
이해는
 
절대
 
헛되지
 
않는다
 
 
 
Day
 
04
 
코랩
 
세션
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
1.
 
논의
 
주제
 
●
 
RAG(Retrieval-Augmented
 
Generation)
 
시스템
 
구현
 
과정에서의
 
실무적
 
난이도와
 
고려
 
요소
 
●
 
청킹
(
chunking)
 
전략과
 
RecursiveCharacterT extSplitter
 
사용
 
이유
 
●
 
임베딩
,
 
유사도
 
검색
,
 
Top-K
 
결과의
 
한계와
 
고도화
 
필요성
 
●
 
프로젝트
 
관점에서
 
RAG
 
적용
 
시
 
데이터
 
도메인별
 
난이도
 
차이
 
●
 
현업에서의
 
라이브러리
 
사용
 
방식과
 
“
정답
 
템플릿
”
에
 
대한
 
오해
 
●
 
그래프
 
RAG
 
등
 
고급
 
기법의
 
효용성과
 
비용
 
대비
 
성능
 
문제
 
2.
 
팀원별
 
핵심
 
아이디어
 
●
 
화자
 
1
 
○
 
RAG
 
구현
 
시
 
함수
 
구조와
 
흐름을
 
이해하는
 
것이
 
초반에
 
가장
 
어렵다고
 
언급
 
○
 
단순히
 
툴을
 
쓰는
 
수준이
 
아니라
 
직접
 
구현해야
 
한다는
 
점에서
 
프로젝트
 
난이도를
 
체감
 
○
 
데이터
 
양과
 
도메인이
 
복잡해질수록
 
성능
 
튜닝이
 
어려워질
 
것이라는
 
우려
 
제기
 
●
 
 
●
 
화자
 
2
 
○
 
RecursiveCharacterT extSplitter
를
 
반복적으로
 
사용하는
 
이유에
 
대한
 
의문
 
제기
 
○
 
일반
 
splitter
 
대비
 
overlap
과
 
문맥
 
유지
 
측면에서의
 
장점에
 
주목
 
○
 
그래프
 
RAG
의
 
효율성과
 
구축
 
비용에
 
대한
 
질문
 
제시
 
●
 
 
●
 
화자
 
3
 
○
 
기본
 
RAG
 
구현은
 
어렵지
 
않으나
,
 
실무
 
수준
(90%
 
이상
 
정확도
)
을
 
달성하는
 
것이
 
진짜
 
난이도라고
 
강조
 
○
 
보험
 
약관
 
사례를
 
통해
 
도메인별
 
문서
 
구조
 
차이가
 
검색
 
품질에
 
큰
 
영향을
 
미친다고
 
설명
 
○
 
청킹
,
 
ID
 
설계
,
 
특약
/
기본약관
 
분리
 
등
 
데이터
 
설계
 
전략의
 
중요성
 
강조
 
○
 
“
정답
 
템플릿은
 
없으며
,
 
라이브러리는
 
계속
 
변한다
”
는
 
관점
 
제시
 
●
 
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
●
 
화자
 
4
 
○
 
고도화된
 
방법은
 
성능은
 
좋지만
 
구축
 
비용과
 
시간이
 
증가할
 
수
 
있음을
 
언급
 
○
 
논문
 
기반
 
기법을
 
그대로
 
활용해
 
성능을
 
비교해보는
 
접근
 
제안
 
○
 
수학적
 
이해보다
 
개념
 
이해와
 
코드
 
활용이
 
더
 
중요하다는
 
입장
 
●
 
 
●
 
화자
 
6
 
○
 
RAG
는
 
단순한
 
백엔드
 
코딩이
 
아니라
 
언어적
 
이해와
 
데이터
 
가공
 
역량이
 
요구된다고
 
평가
 
○
 
프로젝트에서
 
시간이
 
지연될
 
수
 
있는
 
요소로
 
청킹
,
 
임베딩
 
모델
 
선택
,
 
성능
 
테스트를
 
지적
 
○
 
프롬프트
 
활용
 
경험을
 
공유하며
,
 
최근
 
LLM
은
 
질문을
 
단순화해도
 
의도를
 
잘
 
파악한다고
 
설명
 
○
 
프로젝트
 
난이도는
 
“
누구를
 
사용자로
 
설정하느냐
(
B2C
 
vs
 
내부용
)”
에
 
따라
 
크게
 
달라진다고
 
언급
 
●
 
 
3.
 
논의
 
과정
 
●
 
초기에는
 
미션
 
수행
 
중
 
막혔던
 
함수
 
구조와
 
청킹
 
방식에
 
대한
 
질문에서
 
시작
 
●
 
RecursiveCharacterT extSplitter
의
 
사용
 
이유와
 
다른
 
스플리터
 
대비
 
장점에
 
대한
 
기술적
 
논의로
 
확장
 
●
 
RAG
 
기본
 
구조
(
청킹
 
→
 
임베딩
 
→
 
유사도
 
검색
)
는
 
단순하지만
,
 
Top-K
 
결과의
 
품질
 
문제
 
제기
 
●
 
실무
 
사례
(
보험
 
약관
,
 
금융
,
 
법률
)
를
 
통해
 
데이터
 
비정형성
,
 
도메인
 
지식
 
부족이
 
성능
 
저하로
 
이어질
 
수
 
있음을
 
공유
 
●
 
그래프
 
RAG,
 
논문
 
기반
 
기법
,
 
최신
 
모델
 
활용
 
등
 
고도화
 
방안
 
논의
 
●
 
“
현업에서는
 
라이브러리를
 
어떻게
 
쓰는가
”,
 
“
과제용
 
코드와
 
실무
 
코드의
 
차이
”
에
 
대한
 
질문과
 
답변
 
●
 
프롬프트
 
사용
 
전략
,
 
모델
 
선택
(
GPT,
 
Gemini,
 
Claude
 
등
)
에
 
대한
 
경험
 
공유
 
●
 
프로젝트
 
주제
 
선정
 
시
 
난이도
 
조절과
 
현실적인
 
범위
 
설정의
 
중요성으로
 
논의가
 
마무리됨
 
4.
 
최종
 
논의
 
결과
 
및
 
회고
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
●
 
RAG
는
 
개념적으로는
 
단순하지만
,
 
실제
 
프로젝트에서는
 
데이터
 
품질과
 
구조
 
설계가
 
성능을
 
좌우함
 
●
 
청킹
 
전략
,
 
overlap,
 
ID
 
설계
,
 
도메인
 
이해가
 
핵심
 
역량으로
 
확인됨
 
●
 
“
모범
 
템플릿
”
이나
 
“
정답
 
코드
”
는
 
존재하지
 
않으며
,
 
라이브러리와
 
방법론은
 
지속적으로
 
변화함
 
●
 
초기
 
프로젝트는
 
80%
 
수준의
 
구현을
 
목표로
 
하고
,
 
고도화는
 
비용
 
대비
 
효과를
 
고려해야
 
함
 
●
 
수업과
 
미션을
 
통해
 
RAG
의
 
가능성과
 
동시에
 
실무적
 
난이도를
 
체감했다는
 
점에서
 
학습
 
효과가
 
컸다는
 
공감대
 
형성
 
●
 
반복
 
실습과
 
다양한
 
시도가
 
결국
 
개인별
 
노하우를
 
만드는
 
핵심이라는
 
점에
 
의견이
 
모아짐
 
 
 
Day
 
05
 
코랩
 
세션
 
 
1.
 
논의
 
주제
 
벡터
 
임베딩과
 
행렬
 
연산의
 
기본
 
개념
 
이해
 
코사인
 
유사도
(
cosine
 
similarity)
를
 
활용한
 
데이터
 
유사도
 
판단
 
원리
 
이미지
·
텍스트
 
임베딩에서
 
차원
 
수
(
예
:
 
512
차원
)
의
 
의미
 
행렬의
 
행
(
row)
과
 
열
(
column)
이
 
의미하는
 
데이터
 
구조
 
프롬프트
 
엔지니어링에서
 
마크다운
,
 
공백
,
 
구조화의
 
영향
 
실무와
 
면접
 
관점에서의
 
“
이해하고
 
쓰는
 
것
”
의
 
차이
 
---
 
2.
 
팀원별
 
핵심
 
아이디어
 
화자
 
1
 
벡터
 
유사도는
 
코사인
 
유사도를
 
기준으로
 
0~1
 
사이
 
값으로
 
해석해야
 
함을
 
강조
 
행렬
 
곱
,
 
차원
,
 
dim
 
설정의
 
의미를
 
이해하지
 
못하면
 
“
메소드만
 
쓰는
 
상태
”
에
 
머무른다고
 
지적
 
임베딩
 
차원
 
수
(512
 
등
)
는
 
절대적인
 
값이
 
아니라
 
문제
 
난이도와
 
목표에
 
따라
 
달라지는
 
설계
 
요소라고
 
설명
 
마크다운
 
구조
(
H
 
태그
,
 
코드
 
블록
)
가
 
LLM
 
이해도에
 
실질적인
 
영향을
 
준다고
 
강조
 
화자
 
3
 
가중치와
 
행렬
 
곱을
 
통해
 
특징
 
간
 
차이를
 
증폭시키는
 
방식
 
설명
 
차원
 
축소는
 
모델이
 
입력
 
데이터를
 
이해하기
 
쉬운
 
형태로
 
만드는
 
과정이라는
 
관점
 
제시
 
화자
 
4
 
행과
 
열의
 
증가가
 
어떤
 
의미를
 
갖는지에
 
대한
 
기초적인
 
질문
 
제기
 
엔터
,
 
스페이스
,
 
마크다운
 
문법이
 
모델
 
성능에
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

 
 
영향을
 
주는지에
 
대한
 
실무적
 
궁금증
 
공유
 
화자
 
5
 
행렬
 
크기
 
변화
(
예
:
 
3×3
 
→
 
4×4)
가
 
의미하는
 
바에
 
대해
 
질문하며
 
데이터
 
구조
 
이해를
 
시도
 
---
 
3.
 
논의
 
과정
 
논의는
 
벡터
 
임베딩과
 
유사도
 
계산이라는
 
기술적
 
질문에서
 
출발했다
.
 
이미지와
 
텍스트가
 
어떻게
 
같은
 
벡터
 
공간에
 
저장되고
,
 
“
비슷함
”
을
 
어떻게
 
판단하는지에
 
대한
 
질문을
 
계기로
 
코사인
 
유사도의
 
개념이
 
상세히
 
설명되었다
.
 
이후
 
행렬
 
곱의
 
결과
 
형태
,
 
차원의
 
의미
,
 
dim
과
 
keepdim
 
옵션이
 
왜
 
필요한지로
 
논의가
 
확장되었다
.
 
단순히
 
“
값이
 
크면
 
비슷하다
”
가
 
아니라
,
 
벡터
 
간
 
각도를
 
기준으로
 
해석해야
 
한다는
 
점이
 
반복적으로
 
강조되었다
.
 
중반
 
이후에는
 
차원
 
축소와
 
특징
(
feature)
의
 
개념으로
 
논의가
 
이어졌다
.
 
고해상도
 
이미지를
 
그대로
 
쓰는
 
것이
 
아니라
,
 
목적에
 
맞는
 
핵심
 
특징만
 
추출하는
 
것이
 
왜
 
중요한지
,
 
그리고
 
그
 
결과가
 
임베딩
 
차원
 
수로
 
나타난다는
 
설명이
 
이어졌다
.
 
후반부에는
 
프롬프트
 
엔지니어링으로
 
주제가
 
이동했다
.
 
마크다운
 
구조
,
 
H
 
태그
,
 
코드
 
블록
,
 
공백
 
처리
 
등이
 
LLM
의
 
이해도와
 
응답
 
품질에
 
영향을
 
미친다는
 
실무적
 
경험과
 
관련
 
연구
 
사례가
 
공유되었다
.
 
이는
 
검색엔진
 
최적화
(
SEO)
와
 
유사한
 
관점에서
 
설명되며
,
 
문서
 
구조화의
 
중요성으로
 
연결되었다
.
 
---
 
4.
 
최종
 
논의
 
결과
 
및
 
회고
 
벡터
 
임베딩과
 
코사인
 
유사도는
 
“
값을
 
쓰는
 
법
”
보다
 
“
왜
 
그렇게
 
계산되는지
”
를
 
이해하는
 
것이
 
중요하다는
 
데
 
의견이
 
모아졌다
.
 
행렬의
 
행과
 
열은
 
각각
 
데이터의
 
개수와
 
특징의
 
개수를
 
의미하며
,
 
이는
 
엑셀
 
테이블이나
 
DB
 
구조로
 
생각하면
 
이해가
 
쉬워진다
.
 
임베딩
 
차원
 
수는
 
고정된
 
정답이
 
아니라
 
문제
 
정의와
 
목표
 
정밀도에
 
따라
 
달라지는
 
설계
 
선택이다
.
 
실무에서는
 
라이브러리를
 
활용해
 
빠르게
 
결과를
 
내는
 
것도
 
중요하지만
,
 
면접이나
 
설계
 
단계에서는
 
원리
 
이해가
 
 नण  
정적인
 
차이를
 
만든다
.
 
프롬프트
 
엔지니어링에서도
 
구조화된
 
입력
(
마크다운
,
 
코드
 
블록
,
 
명확한
 
구분
)
이
 
모델
 
성능과
 
직결된다는
 
점을
 
확인했다
.
 
전체적으로
 
이번
 
논의는
 
“AI
를
 
사용한다
”
에서
 
“AI
가
 
어떻게
 
작동하는지를
 
이해한다
”
로
 
사고
 
수준을
 
한
 
단계
 
끌어올리는
 
계기가
 
되었으며
,
 
향후
 
프로젝트와
 
면접
 
준비
 
모두에
 
직접적으로
 
연결될
 
수
 
있는
 
학습이라는
 
점에서
 
의미
 
있는
 
세션으로
 
정리되었다
.
 
 
*저작권
 
주의
 
(주)업스테이지가
 
제공하는
 
모든
 
교육
 
콘텐츠의
 
지식재산권은
 
운영
 
주체인
 
(주)업스테이지에게
 
귀속되어
 
있습니다.
 
콘텐츠
 
일부
 
또는
 
전부를
 
복사,
 
복제,
 
판매,
 
재판매
 
공개,
 
공유
 
등을
 
할
 
수
 
없습니다.
 

